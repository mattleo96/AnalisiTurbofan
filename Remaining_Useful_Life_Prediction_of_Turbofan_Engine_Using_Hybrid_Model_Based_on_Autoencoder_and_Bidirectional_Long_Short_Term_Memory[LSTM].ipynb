{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Remaining Useful Life Prediction of Turbofan Engine Using Hybrid Model Based on Autoencoder and Bidirectional Long Short-Term Memory[LSTM].ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnvs3cEtWRl4",
        "outputId": "2e55036f-4be4-4ea2-f86b-3de49ef07820"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LSTM,Dropout,GRU,MaxPooling1D,Flatten,concatenate\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Concatenate,Bidirectional\n",
        "from keras.layers.convolutional import Conv1D\n",
        "import tensorflow as tf\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed,Activation\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras import Input,Model\n",
        "\n",
        "FD1_train = pd.read_csv(\"train_FD001.txt\",delimiter=\" \",header = None)\n",
        "FD1_test = pd.read_csv(\"test_FD001.txt\",delimiter=\" \",header = None)\n",
        "RUL_file=pd.read_csv(\"RUL_FD001.txt\",header = None)\n",
        "\n",
        "FD1_test=FD1_test.drop([26, 27], axis = 1)\n",
        "columns = {0:'unit_number',1:'time_in_cycles',2:'opSetting1',3:'opSetting2',4:'opSetting3',5:'sensor1',6:'sensor2',\n",
        "           7:'sensor3',8:'sensor4',9:'sensor5',10:'sensor6',11:'sensor7',12:'sensor8',13:'sensor9',14:'sensor10',\n",
        "           15:'sensor11',16:'sensor12',17:'sensor13',18:'sensor14',19:'sensor15',20:'sensor16',\n",
        "           21:'sensor17',22:'sensor18',23:'sensor19',24:'sensor20',25:'sensor21'}\n",
        "FD1_test.columns=columns\n",
        "FD1_test = FD1_test.rename(columns=columns)\n",
        "FD1_test=FD1_test.drop(columns = ['opSetting1','opSetting2','opSetting3','sensor1','sensor5','sensor6','sensor10','sensor16','sensor18','sensor19','sensor17'], axis =1)\n",
        "\n",
        "\n",
        "\n",
        "FD1_train=FD1_train.drop([26, 27], axis = 1)\n",
        "columns = {0:'unit_number',1:'time_in_cycles',2:'opSetting1',3:'opSetting2',4:'opSetting3',5:'sensor1',6:'sensor2',\n",
        "           7:'sensor3',8:'sensor4',9:'sensor5',10:'sensor6',11:'sensor7',12:'sensor8',13:'sensor9',14:'sensor10',\n",
        "           15:'sensor11',16:'sensor12',17:'sensor13',18:'sensor14',19:'sensor15',20:'sensor16',\n",
        "           21:'sensor17',22:'sensor18',23:'sensor19',24:'sensor20',25:'sensor21'}\n",
        "FD1_train = FD1_train.rename(columns=columns)\n",
        "FD1_train=FD1_train.drop(columns = ['opSetting1','opSetting2','opSetting3','sensor1','sensor5','sensor6','sensor10','sensor16','sensor18','sensor19','sensor17'], axis =1)\n",
        "\n",
        "# calcolo RUL\n",
        "def Calcolo_RUL(df): \n",
        "    df_copy=df.copy()\n",
        "    gruppo=df_copy.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
        "    gruppo.columns = ['unit_number','max_cycles_fu']\n",
        "    df_copy = df_copy.merge(gruppo, on=['unit_number'], how='left')\n",
        "    df['RUL'] = df_copy['max_cycles_fu'] - df_copy['time_in_cycles']\n",
        "    return df\n",
        "Calcolo_RUL(FD1_train)\n",
        "#normalizzazione train test\n",
        "cols_normalize = FD1_train.columns.difference( #non considero unit_number,time_in_cycles,RUL per normalizzazione\n",
        "    ['unit_number', 'time_in_cycles', 'RUL'])  \n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(FD1_train[cols_normalize]),\n",
        "                             columns=cols_normalize,\n",
        "                             index=FD1_train.index)\n",
        "\n",
        "join_df = FD1_train[FD1_train.columns.difference(cols_normalize)].join(norm_train_df)\n",
        "FD1_train = join_df.reindex(columns=FD1_train.columns)\n",
        "\n",
        "cols_normalizetest = FD1_test.columns.difference(  #non considero unit_number,time_in_cyclesper normalizzazione\n",
        "    ['unit_number', 'time_in_cycles'])  \n",
        "\n",
        "norm_train_df_test = pd.DataFrame(min_max_scaler.transform(FD1_test[cols_normalizetest]),\n",
        "                             columns=cols_normalizetest,\n",
        "                             index=FD1_test.index)\n",
        "\n",
        "join_df = FD1_test[FD1_test.columns.difference(cols_normalizetest)].join(norm_train_df_test)\n",
        "FD1_test = join_df.reindex(columns=FD1_test.columns)\n",
        "FD1_test=FD1_test.drop(columns = ['time_in_cycles'], axis =1)\n",
        "data_cols= FD1_test.columns\n",
        "##\n",
        "## reshape dati test\n",
        "def prepare_test_data(df):\n",
        "    data_list = []\n",
        "    for unit_number in df.unit_number.unique():\n",
        "        unit = df[df.unit_number == unit_number]\n",
        "        data_list.append(np.array(unit[data_cols])[-31:, :])\n",
        "    return np.stack(data_list)\n",
        "FD1_test=prepare_test_data(FD1_test)\n",
        "FD1_test=FD1_test[:,:,1:]\n",
        "\n",
        "\n",
        "## upper bound per RUL\n",
        "rul_clip_limit = 120\n",
        "FD1_train=FD1_train.clip(upper=rul_clip_limit)\n",
        "\n",
        "FD1_c=FD1_train.copy()\n",
        "FD1_train = FD1_train.drop(['RUL','time_in_cycles'], axis=1)\n",
        "## reshape dati di train\n",
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    data_array = id_df[seq_cols].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        yield data_array[start:stop, :]\n",
        "\n",
        "seq_gen = (list(gen_sequence(FD1_train[FD1_train['unit_number']==unit_number],31, FD1_train.columns))\n",
        "           for unit_number in FD1_train['unit_number'].unique())\n",
        "\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "\n",
        "\n",
        "seq_array=seq_array[:,:,1:] #elimino unit_number dal train\n",
        "print(seq_array.shape) # dimensione dei dati di train\n",
        "\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "    data_array = id_df[label].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    return data_array[seq_length:num_elements, :]\n",
        "\n",
        "label_gen = [gen_labels(FD1_c[FD1_c['unit_number']==id], 31, ['RUL'])\n",
        "             for id in FD1_c['unit_number'].unique()]\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model= Sequential()\n",
        "model.add(LSTM(100,input_shape=(31,13), activation='tanh', return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(50,input_shape=(31,13), activation='tanh',return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(30))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='RMSprop',metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "#model.fit(seq_array,label_array ,batch_size=200,epochs=70,verbose=1,validation_split=0.1)\n",
        "model.fit(seq_array,label_array ,batch_size=128,epochs=50,verbose=1,validation_split=0.05)\n",
        "y_pred= model.predict(FD1_test)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "RUL_file=pd.read_csv(\"RUL_FD001.txt\",header = None)\n",
        "print(sqrt(mean_squared_error(RUL_file, y_pred)))\n",
        "print(y_pred)\n",
        "print((mean_squared_error(RUL_file, y_pred)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17531, 31, 13)\n",
            "Epoch 1/50\n",
            "131/131 [==============================] - 5s 13ms/step - loss: 4762.4543 - root_mean_squared_error: 76.3167 - val_loss: 1568.8595 - val_root_mean_squared_error: 56.7445\n",
            "Epoch 2/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 1045.2070 - root_mean_squared_error: 53.0019 - val_loss: 722.9019 - val_root_mean_squared_error: 44.4469\n",
            "Epoch 3/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 439.6783 - root_mean_squared_error: 42.4672 - val_loss: 299.7136 - val_root_mean_squared_error: 37.9501\n",
            "Epoch 4/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 304.4015 - root_mean_squared_error: 36.7425 - val_loss: 242.2258 - val_root_mean_squared_error: 33.9659\n",
            "Epoch 5/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 296.0845 - root_mean_squared_error: 33.1840 - val_loss: 255.5892 - val_root_mean_squared_error: 31.2898\n",
            "Epoch 6/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 271.7132 - root_mean_squared_error: 30.7224 - val_loss: 528.0821 - val_root_mean_squared_error: 29.3478\n",
            "Epoch 7/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 263.1441 - root_mean_squared_error: 28.9250 - val_loss: 429.3501 - val_root_mean_squared_error: 27.8476\n",
            "Epoch 8/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 239.0228 - root_mean_squared_error: 27.5074 - val_loss: 249.7518 - val_root_mean_squared_error: 26.6296\n",
            "Epoch 9/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 232.5446 - root_mean_squared_error: 26.3456 - val_loss: 241.4319 - val_root_mean_squared_error: 25.6164\n",
            "Epoch 10/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 224.3984 - root_mean_squared_error: 25.3776 - val_loss: 245.5620 - val_root_mean_squared_error: 24.7633\n",
            "Epoch 11/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 230.5563 - root_mean_squared_error: 24.5642 - val_loss: 299.3814 - val_root_mean_squared_error: 24.0486\n",
            "Epoch 12/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 222.7045 - root_mean_squared_error: 23.8780 - val_loss: 261.3721 - val_root_mean_squared_error: 23.4251\n",
            "Epoch 13/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 219.7424 - root_mean_squared_error: 23.2737 - val_loss: 385.5623 - val_root_mean_squared_error: 22.8792\n",
            "Epoch 14/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 249.5433 - root_mean_squared_error: 22.7657 - val_loss: 295.7946 - val_root_mean_squared_error: 22.4436\n",
            "Epoch 15/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 208.6832 - root_mean_squared_error: 22.3216 - val_loss: 223.1671 - val_root_mean_squared_error: 21.9999\n",
            "Epoch 16/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 206.3759 - root_mean_squared_error: 21.8901 - val_loss: 255.0624 - val_root_mean_squared_error: 21.6041\n",
            "Epoch 17/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 204.3249 - root_mean_squared_error: 21.5060 - val_loss: 230.6326 - val_root_mean_squared_error: 21.2450\n",
            "Epoch 18/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 207.8773 - root_mean_squared_error: 21.1577 - val_loss: 264.5722 - val_root_mean_squared_error: 20.9154\n",
            "Epoch 19/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 192.2168 - root_mean_squared_error: 20.8322 - val_loss: 311.8859 - val_root_mean_squared_error: 20.6138\n",
            "Epoch 20/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 204.3997 - root_mean_squared_error: 20.5438 - val_loss: 243.0652 - val_root_mean_squared_error: 20.3427\n",
            "Epoch 21/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 198.0542 - root_mean_squared_error: 20.2747 - val_loss: 356.6295 - val_root_mean_squared_error: 20.0891\n",
            "Epoch 22/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 208.9717 - root_mean_squared_error: 20.0302 - val_loss: 213.1506 - val_root_mean_squared_error: 19.8766\n",
            "Epoch 23/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 184.5855 - root_mean_squared_error: 19.8137 - val_loss: 243.8131 - val_root_mean_squared_error: 19.6506\n",
            "Epoch 24/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 185.3376 - root_mean_squared_error: 19.5922 - val_loss: 199.7533 - val_root_mean_squared_error: 19.4412\n",
            "Epoch 25/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 185.0625 - root_mean_squared_error: 19.3867 - val_loss: 170.6101 - val_root_mean_squared_error: 19.2377\n",
            "Epoch 26/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 183.6839 - root_mean_squared_error: 19.1867 - val_loss: 324.9450 - val_root_mean_squared_error: 19.0538\n",
            "Epoch 27/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 187.5839 - root_mean_squared_error: 19.0100 - val_loss: 242.8161 - val_root_mean_squared_error: 18.8846\n",
            "Epoch 28/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 180.8326 - root_mean_squared_error: 18.8389 - val_loss: 211.0718 - val_root_mean_squared_error: 18.7156\n",
            "Epoch 29/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 175.5285 - root_mean_squared_error: 18.6717 - val_loss: 434.6795 - val_root_mean_squared_error: 18.5608\n",
            "Epoch 30/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 171.6634 - root_mean_squared_error: 18.5212 - val_loss: 199.1546 - val_root_mean_squared_error: 18.4064\n",
            "Epoch 31/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 170.2439 - root_mean_squared_error: 18.3672 - val_loss: 304.8588 - val_root_mean_squared_error: 18.2609\n",
            "Epoch 32/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 173.2560 - root_mean_squared_error: 18.2244 - val_loss: 204.2054 - val_root_mean_squared_error: 18.1229\n",
            "Epoch 33/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 167.0317 - root_mean_squared_error: 18.0870 - val_loss: 295.2705 - val_root_mean_squared_error: 17.9902\n",
            "Epoch 34/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 181.0234 - root_mean_squared_error: 17.9608 - val_loss: 252.3618 - val_root_mean_squared_error: 17.8679\n",
            "Epoch 35/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 168.3009 - root_mean_squared_error: 17.8363 - val_loss: 178.9949 - val_root_mean_squared_error: 17.7449\n",
            "Epoch 36/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 156.8640 - root_mean_squared_error: 17.7114 - val_loss: 224.1969 - val_root_mean_squared_error: 17.6260\n",
            "Epoch 37/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 165.7229 - root_mean_squared_error: 17.5961 - val_loss: 604.8619 - val_root_mean_squared_error: 17.5249\n",
            "Epoch 38/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 167.9740 - root_mean_squared_error: 17.5009 - val_loss: 198.2113 - val_root_mean_squared_error: 17.4194\n",
            "Epoch 39/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 158.5855 - root_mean_squared_error: 17.3918 - val_loss: 214.8736 - val_root_mean_squared_error: 17.3148\n",
            "Epoch 40/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 159.4528 - root_mean_squared_error: 17.2883 - val_loss: 232.4757 - val_root_mean_squared_error: 17.2131\n",
            "Epoch 41/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 156.0130 - root_mean_squared_error: 17.1876 - val_loss: 418.2243 - val_root_mean_squared_error: 17.1172\n",
            "Epoch 42/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 161.1372 - root_mean_squared_error: 17.0977 - val_loss: 198.8945 - val_root_mean_squared_error: 17.0273\n",
            "Epoch 43/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 156.5883 - root_mean_squared_error: 17.0037 - val_loss: 157.1835 - val_root_mean_squared_error: 16.9350\n",
            "Epoch 44/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 154.9301 - root_mean_squared_error: 16.9110 - val_loss: 366.3780 - val_root_mean_squared_error: 16.8481\n",
            "Epoch 45/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 155.1914 - root_mean_squared_error: 16.8275 - val_loss: 253.2704 - val_root_mean_squared_error: 16.7639\n",
            "Epoch 46/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 154.9612 - root_mean_squared_error: 16.7431 - val_loss: 273.3895 - val_root_mean_squared_error: 16.6850\n",
            "Epoch 47/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 150.7983 - root_mean_squared_error: 16.6639 - val_loss: 227.8027 - val_root_mean_squared_error: 16.6044\n",
            "Epoch 48/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 147.3675 - root_mean_squared_error: 16.5833 - val_loss: 163.5467 - val_root_mean_squared_error: 16.5258\n",
            "Epoch 49/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 148.3796 - root_mean_squared_error: 16.5053 - val_loss: 208.1628 - val_root_mean_squared_error: 16.4490\n",
            "Epoch 50/50\n",
            "131/131 [==============================] - 1s 7ms/step - loss: 142.5751 - root_mean_squared_error: 16.4286 - val_loss: 214.7113 - val_root_mean_squared_error: 16.3750\n",
            "13.524321054995537\n",
            "[[115.22212  ]\n",
            " [113.79506  ]\n",
            " [ 52.6344   ]\n",
            " [ 87.280106 ]\n",
            " [107.518486 ]\n",
            " [ 99.556175 ]\n",
            " [106.58793  ]\n",
            " [ 88.003716 ]\n",
            " [109.96026  ]\n",
            " [ 92.40711  ]\n",
            " [ 79.34875  ]\n",
            " [104.72592  ]\n",
            " [ 96.98792  ]\n",
            " [102.35252  ]\n",
            " [111.94263  ]\n",
            " [101.279976 ]\n",
            " [ 56.35495  ]\n",
            " [ 31.856264 ]\n",
            " [100.051285 ]\n",
            " [ 19.945421 ]\n",
            " [ 52.917698 ]\n",
            " [114.97187  ]\n",
            " [117.30904  ]\n",
            " [ 20.789463 ]\n",
            " [112.981895 ]\n",
            " [111.89831  ]\n",
            " [ 72.120865 ]\n",
            " [ 94.70652  ]\n",
            " [ 95.84026  ]\n",
            " [ 99.53307  ]\n",
            " [ 13.316426 ]\n",
            " [ 49.054005 ]\n",
            " [113.57502  ]\n",
            " [  7.0534124]\n",
            " [ 19.020597 ]\n",
            " [ 29.609392 ]\n",
            " [ 28.790997 ]\n",
            " [ 59.641064 ]\n",
            " [115.61306  ]\n",
            " [ 39.818394 ]\n",
            " [ 29.012264 ]\n",
            " [ 10.247719 ]\n",
            " [ 59.912857 ]\n",
            " [ 96.143845 ]\n",
            " [ 90.734726 ]\n",
            " [ 43.982845 ]\n",
            " [104.07761  ]\n",
            " [ 77.9281   ]\n",
            " [ 21.545301 ]\n",
            " [ 93.92306  ]\n",
            " [102.0923   ]\n",
            " [ 33.760296 ]\n",
            " [ 27.598143 ]\n",
            " [115.42442  ]\n",
            " [115.346855 ]\n",
            " [ 25.496025 ]\n",
            " [104.25264  ]\n",
            " [ 46.997887 ]\n",
            " [108.30132  ]\n",
            " [108.74611  ]\n",
            " [ 21.005194 ]\n",
            " [ 44.02126  ]\n",
            " [ 69.51528  ]\n",
            " [ 21.337236 ]\n",
            " [115.70495  ]\n",
            " [ 18.631956 ]\n",
            " [115.10752  ]\n",
            " [ 10.553435 ]\n",
            " [107.93994  ]\n",
            " [ 88.07466  ]\n",
            " [110.062744 ]\n",
            " [ 64.865265 ]\n",
            " [112.887344 ]\n",
            " [109.416084 ]\n",
            " [106.561    ]\n",
            " [  8.789911 ]\n",
            " [ 29.586475 ]\n",
            " [118.52572  ]\n",
            " [ 64.49571  ]\n",
            " [102.50138  ]\n",
            " [ 14.111122 ]\n",
            " [ 10.728931 ]\n",
            " [117.0841   ]\n",
            " [ 72.89367  ]\n",
            " [116.229256 ]\n",
            " [107.966995 ]\n",
            " [106.80233  ]\n",
            " [112.87094  ]\n",
            " [111.14013  ]\n",
            " [ 29.186548 ]\n",
            " [ 31.765    ]\n",
            " [ 30.071497 ]\n",
            " [ 53.07961  ]\n",
            " [ 73.73336  ]\n",
            " [108.29827  ]\n",
            " [103.45315  ]\n",
            " [ 98.04761  ]\n",
            " [ 81.38111  ]\n",
            " [108.1631   ]\n",
            " [ 18.841457 ]]\n",
            "182.9072599985956\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}