{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A Remaining Useful Life Prognosis of Turbofan Engine Using Temporal and Spatial Feature Fusion[CNN].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flb_cCznmFg_",
        "outputId": "6d0b1f52-a61c-4e8d-b312-305e39853fc8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LSTM,Dropout,GRU,MaxPooling1D,Flatten,concatenate\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Concatenate,Bidirectional\n",
        "from keras.layers.convolutional import Conv1D\n",
        "import tensorflow as tf\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed,Activation\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras import Input,Model\n",
        "\n",
        "FD1_train = pd.read_csv(\"train_FD001.txt\",delimiter=\" \",header = None)\n",
        "FD1_test = pd.read_csv(\"test_FD001.txt\",delimiter=\" \",header = None)\n",
        "RUL_file=pd.read_csv(\"RUL_FD001.txt\",header = None)\n",
        "\n",
        "FD1_test=FD1_test.drop([26, 27], axis = 1)\n",
        "columns = {0:'unit_number',1:'time_in_cycles',2:'opSetting1',3:'opSetting2',4:'opSetting3',5:'sensor1',6:'sensor2',\n",
        "           7:'sensor3',8:'sensor4',9:'sensor5',10:'sensor6',11:'sensor7',12:'sensor8',13:'sensor9',14:'sensor10',\n",
        "           15:'sensor11',16:'sensor12',17:'sensor13',18:'sensor14',19:'sensor15',20:'sensor16',\n",
        "           21:'sensor17',22:'sensor18',23:'sensor19',24:'sensor20',25:'sensor21'}\n",
        "FD1_test.columns=columns\n",
        "FD1_test = FD1_test.rename(columns=columns)\n",
        "FD1_test=FD1_test.drop(columns = ['opSetting1','opSetting2','opSetting3','sensor1','sensor5','sensor6','sensor10','sensor16','sensor18','sensor19','sensor17'], axis =1)\n",
        "\n",
        "\n",
        "\n",
        "FD1_train=FD1_train.drop([26, 27], axis = 1)\n",
        "columns = {0:'unit_number',1:'time_in_cycles',2:'opSetting1',3:'opSetting2',4:'opSetting3',5:'sensor1',6:'sensor2',\n",
        "           7:'sensor3',8:'sensor4',9:'sensor5',10:'sensor6',11:'sensor7',12:'sensor8',13:'sensor9',14:'sensor10',\n",
        "           15:'sensor11',16:'sensor12',17:'sensor13',18:'sensor14',19:'sensor15',20:'sensor16',\n",
        "           21:'sensor17',22:'sensor18',23:'sensor19',24:'sensor20',25:'sensor21'}\n",
        "FD1_train = FD1_train.rename(columns=columns)\n",
        "FD1_train=FD1_train.drop(columns = ['opSetting1','opSetting2','opSetting3','sensor1','sensor5','sensor6','sensor10','sensor16','sensor18','sensor19','sensor17'], axis =1)\n",
        "\n",
        "# calcolo RUL\n",
        "def Calcolo_RUL(df): \n",
        "    df_copy=df.copy()\n",
        "    gruppo=df_copy.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
        "    gruppo.columns = ['unit_number','max_cycles_fu']\n",
        "    df_copy = df_copy.merge(gruppo, on=['unit_number'], how='left')\n",
        "    df['RUL'] = df_copy['max_cycles_fu'] - df_copy['time_in_cycles']\n",
        "    return df\n",
        "Calcolo_RUL(FD1_train)\n",
        "#normalizzazione train test\n",
        "cols_normalize = FD1_train.columns.difference( #non considero unit_number,time_in_cycles,RUL per normalizzazione\n",
        "    ['unit_number', 'time_in_cycles', 'RUL'])  \n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(FD1_train[cols_normalize]),\n",
        "                             columns=cols_normalize,\n",
        "                             index=FD1_train.index)\n",
        "\n",
        "join_df = FD1_train[FD1_train.columns.difference(cols_normalize)].join(norm_train_df)\n",
        "FD1_train = join_df.reindex(columns=FD1_train.columns)\n",
        "\n",
        "cols_normalizetest = FD1_test.columns.difference(  #non considero unit_number,time_in_cyclesper normalizzazione\n",
        "    ['unit_number', 'time_in_cycles'])  \n",
        "\n",
        "norm_train_df_test = pd.DataFrame(min_max_scaler.transform(FD1_test[cols_normalizetest]),\n",
        "                             columns=cols_normalizetest,\n",
        "                             index=FD1_test.index)\n",
        "\n",
        "join_df = FD1_test[FD1_test.columns.difference(cols_normalizetest)].join(norm_train_df_test)\n",
        "FD1_test = join_df.reindex(columns=FD1_test.columns)\n",
        "FD1_test=FD1_test.drop(columns = ['time_in_cycles'], axis =1)\n",
        "data_cols= FD1_test.columns\n",
        "##\n",
        "## reshape dati test\n",
        "def prepare_test_data(df):\n",
        "    data_list = []\n",
        "    for unit_number in df.unit_number.unique():\n",
        "        unit = df[df.unit_number == unit_number]\n",
        "        data_list.append(np.array(unit[data_cols])[-31:, :])\n",
        "    return np.stack(data_list)\n",
        "FD1_test=prepare_test_data(FD1_test)\n",
        "FD1_test=FD1_test[:,:,1:]\n",
        "\n",
        "\n",
        "## upper bound per RUL\n",
        "rul_clip_limit = 120\n",
        "FD1_train=FD1_train.clip(upper=rul_clip_limit)\n",
        "\n",
        "FD1_c=FD1_train.copy()\n",
        "FD1_train = FD1_train.drop(['RUL','time_in_cycles'], axis=1)\n",
        "## reshape dati di train\n",
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    data_array = id_df[seq_cols].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        yield data_array[start:stop, :]\n",
        "\n",
        "seq_gen = (list(gen_sequence(FD1_train[FD1_train['unit_number']==unit_number],31, FD1_train.columns))\n",
        "           for unit_number in FD1_train['unit_number'].unique())\n",
        "\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "\n",
        "\n",
        "seq_array=seq_array[:,:,1:] #elimino unit_number dal train\n",
        "print(seq_array.shape) # dimensione dei dati di train\n",
        "\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "    data_array = id_df[label].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    return data_array[seq_length:num_elements, :]\n",
        "\n",
        "label_gen = [gen_labels(FD1_c[FD1_c['unit_number']==id], 31, ['RUL'])\n",
        "             for id in FD1_c['unit_number'].unique()]\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model= Sequential()\n",
        "\n",
        "model.add(Conv1D(128,1,padding='same',activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2,padding='same',strides=2))\n",
        "model.add(Conv1D(64,1,padding='same',activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2,padding='same',strides=2))\n",
        "model.add(Conv1D(32,1,padding='same',activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2,padding='same',strides=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,kernel_initializer='uniform', activation=\"relu\"))\n",
        "model.add(Dense(30,kernel_initializer='uniform', activation=\"relu\"))\n",
        "model.add(Dense(1,kernel_initializer='uniform', activation=\"relu\"))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam',metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "model.fit(seq_array,label_array ,batch_size=200,epochs=70,verbose=1,validation_split=0.05)\n",
        "y_pred= model.predict(FD1_test)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "RUL_file=pd.read_csv(\"RUL_FD001.txt\",header = None)\n",
        "print(sqrt(mean_squared_error(RUL_file, y_pred)))\n",
        "print(y_pred)\n",
        "print((mean_squared_error(RUL_file, y_pred)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17531, 31, 13)\n",
            "Epoch 1/70\n",
            "84/84 [==============================] - 4s 28ms/step - loss: 6424.4510 - root_mean_squared_error: 85.4559 - val_loss: 1410.0184 - val_root_mean_squared_error: 65.1731\n",
            "Epoch 2/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 1099.3376 - root_mean_squared_error: 60.3493 - val_loss: 549.9597 - val_root_mean_squared_error: 50.3936\n",
            "Epoch 3/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 545.0181 - root_mean_squared_error: 48.1138 - val_loss: 443.2097 - val_root_mean_squared_error: 43.1438\n",
            "Epoch 4/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 456.8235 - root_mean_squared_error: 41.8362 - val_loss: 352.5923 - val_root_mean_squared_error: 38.7892\n",
            "Epoch 5/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 409.7312 - root_mean_squared_error: 37.9157 - val_loss: 349.9214 - val_root_mean_squared_error: 35.7899\n",
            "Epoch 6/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 360.2688 - root_mean_squared_error: 35.1464 - val_loss: 327.0835 - val_root_mean_squared_error: 33.5322\n",
            "Epoch 7/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 297.6253 - root_mean_squared_error: 33.0144 - val_loss: 253.2989 - val_root_mean_squared_error: 31.6930\n",
            "Epoch 8/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 226.6391 - root_mean_squared_error: 31.2463 - val_loss: 219.3381 - val_root_mean_squared_error: 30.0975\n",
            "Epoch 9/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 198.2290 - root_mean_squared_error: 29.7201 - val_loss: 208.2594 - val_root_mean_squared_error: 28.7634\n",
            "Epoch 10/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 192.0084 - root_mean_squared_error: 28.4460 - val_loss: 204.3091 - val_root_mean_squared_error: 27.6282\n",
            "Epoch 11/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 183.6431 - root_mean_squared_error: 27.3555 - val_loss: 203.1278 - val_root_mean_squared_error: 26.6553\n",
            "Epoch 12/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 184.2223 - root_mean_squared_error: 26.4217 - val_loss: 211.2098 - val_root_mean_squared_error: 25.8137\n",
            "Epoch 13/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 174.2430 - root_mean_squared_error: 25.6075 - val_loss: 197.3950 - val_root_mean_squared_error: 25.0736\n",
            "Epoch 14/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 171.7907 - root_mean_squared_error: 24.8903 - val_loss: 196.4396 - val_root_mean_squared_error: 24.4163\n",
            "Epoch 15/70\n",
            "84/84 [==============================] - 2s 23ms/step - loss: 168.5484 - root_mean_squared_error: 24.2529 - val_loss: 209.0961 - val_root_mean_squared_error: 23.8288\n",
            "Epoch 16/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 169.4065 - root_mean_squared_error: 23.6832 - val_loss: 198.8075 - val_root_mean_squared_error: 23.3017\n",
            "Epoch 17/70\n",
            "84/84 [==============================] - 2s 23ms/step - loss: 165.9625 - root_mean_squared_error: 23.1689 - val_loss: 225.7905 - val_root_mean_squared_error: 22.8278\n",
            "Epoch 18/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 169.3324 - root_mean_squared_error: 22.7084 - val_loss: 198.9706 - val_root_mean_squared_error: 22.3955\n",
            "Epoch 19/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 166.2939 - root_mean_squared_error: 22.2860 - val_loss: 203.6971 - val_root_mean_squared_error: 21.9981\n",
            "Epoch 20/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 168.1099 - root_mean_squared_error: 21.8984 - val_loss: 215.4290 - val_root_mean_squared_error: 21.6361\n",
            "Epoch 21/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 171.3836 - root_mean_squared_error: 21.5468 - val_loss: 194.5443 - val_root_mean_squared_error: 21.3046\n",
            "Epoch 22/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 159.7820 - root_mean_squared_error: 21.2180 - val_loss: 195.5856 - val_root_mean_squared_error: 20.9912\n",
            "Epoch 23/70\n",
            "84/84 [==============================] - 2s 23ms/step - loss: 161.3224 - root_mean_squared_error: 20.9116 - val_loss: 196.8673 - val_root_mean_squared_error: 20.7023\n",
            "Epoch 24/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 155.3683 - root_mean_squared_error: 20.6269 - val_loss: 196.8825 - val_root_mean_squared_error: 20.4306\n",
            "Epoch 25/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 160.8940 - root_mean_squared_error: 20.3617 - val_loss: 194.8303 - val_root_mean_squared_error: 20.1753\n",
            "Epoch 26/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 155.3914 - root_mean_squared_error: 20.1095 - val_loss: 197.4416 - val_root_mean_squared_error: 19.9364\n",
            "Epoch 27/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 159.5720 - root_mean_squared_error: 19.8754 - val_loss: 199.9650 - val_root_mean_squared_error: 19.7127\n",
            "Epoch 28/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 155.8781 - root_mean_squared_error: 19.6552 - val_loss: 202.4552 - val_root_mean_squared_error: 19.5031\n",
            "Epoch 29/70\n",
            "84/84 [==============================] - 2s 23ms/step - loss: 155.5406 - root_mean_squared_error: 19.4491 - val_loss: 198.6900 - val_root_mean_squared_error: 19.3051\n",
            "Epoch 30/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 155.5866 - root_mean_squared_error: 19.2543 - val_loss: 192.8847 - val_root_mean_squared_error: 19.1165\n",
            "Epoch 31/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 154.8937 - root_mean_squared_error: 19.0682 - val_loss: 197.4257 - val_root_mean_squared_error: 18.9377\n",
            "Epoch 32/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 152.2520 - root_mean_squared_error: 18.8913 - val_loss: 207.3324 - val_root_mean_squared_error: 18.7690\n",
            "Epoch 33/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 153.8828 - root_mean_squared_error: 18.7252 - val_loss: 196.2703 - val_root_mean_squared_error: 18.6078\n",
            "Epoch 34/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 155.3386 - root_mean_squared_error: 18.5667 - val_loss: 198.5980 - val_root_mean_squared_error: 18.4562\n",
            "Epoch 35/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 147.6922 - root_mean_squared_error: 18.4157 - val_loss: 202.7015 - val_root_mean_squared_error: 18.3102\n",
            "Epoch 36/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 148.7809 - root_mean_squared_error: 18.2716 - val_loss: 196.8560 - val_root_mean_squared_error: 18.1720\n",
            "Epoch 37/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 149.8097 - root_mean_squared_error: 18.1356 - val_loss: 214.0908 - val_root_mean_squared_error: 18.0417\n",
            "Epoch 38/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 149.9226 - root_mean_squared_error: 18.0069 - val_loss: 196.3462 - val_root_mean_squared_error: 17.9134\n",
            "Epoch 39/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 149.1119 - root_mean_squared_error: 17.8801 - val_loss: 209.8117 - val_root_mean_squared_error: 17.7913\n",
            "Epoch 40/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 154.6535 - root_mean_squared_error: 17.7608 - val_loss: 205.9628 - val_root_mean_squared_error: 17.6765\n",
            "Epoch 41/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 150.6423 - root_mean_squared_error: 17.6467 - val_loss: 199.0289 - val_root_mean_squared_error: 17.5641\n",
            "Epoch 42/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 147.3214 - root_mean_squared_error: 17.5346 - val_loss: 202.5269 - val_root_mean_squared_error: 17.4550\n",
            "Epoch 43/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 142.2589 - root_mean_squared_error: 17.4259 - val_loss: 204.1031 - val_root_mean_squared_error: 17.3513\n",
            "Epoch 44/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 144.9686 - root_mean_squared_error: 17.3235 - val_loss: 200.7059 - val_root_mean_squared_error: 17.2504\n",
            "Epoch 45/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 141.7400 - root_mean_squared_error: 17.2234 - val_loss: 200.5292 - val_root_mean_squared_error: 17.1523\n",
            "Epoch 46/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 139.5691 - root_mean_squared_error: 17.1261 - val_loss: 215.1920 - val_root_mean_squared_error: 17.0591\n",
            "Epoch 47/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 143.8098 - root_mean_squared_error: 17.0344 - val_loss: 206.4590 - val_root_mean_squared_error: 16.9680\n",
            "Epoch 48/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 143.3028 - root_mean_squared_error: 16.9443 - val_loss: 202.9591 - val_root_mean_squared_error: 16.8840\n",
            "Epoch 49/70\n",
            "84/84 [==============================] - 2s 24ms/step - loss: 143.0275 - root_mean_squared_error: 16.8611 - val_loss: 202.5676 - val_root_mean_squared_error: 16.8017\n",
            "Epoch 50/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 137.8104 - root_mean_squared_error: 16.7787 - val_loss: 213.4725 - val_root_mean_squared_error: 16.7199\n",
            "Epoch 51/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 143.7565 - root_mean_squared_error: 16.6984 - val_loss: 205.5477 - val_root_mean_squared_error: 16.6427\n",
            "Epoch 52/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 142.4539 - root_mean_squared_error: 16.6222 - val_loss: 203.3561 - val_root_mean_squared_error: 16.5664\n",
            "Epoch 53/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 143.4459 - root_mean_squared_error: 16.5465 - val_loss: 206.6161 - val_root_mean_squared_error: 16.4917\n",
            "Epoch 54/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 137.7499 - root_mean_squared_error: 16.4715 - val_loss: 210.5340 - val_root_mean_squared_error: 16.4199\n",
            "Epoch 55/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 139.6647 - root_mean_squared_error: 16.4009 - val_loss: 203.4536 - val_root_mean_squared_error: 16.3510\n",
            "Epoch 56/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 140.8166 - root_mean_squared_error: 16.3324 - val_loss: 206.9156 - val_root_mean_squared_error: 16.2830\n",
            "Epoch 57/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 139.4319 - root_mean_squared_error: 16.2651 - val_loss: 214.0002 - val_root_mean_squared_error: 16.2177\n",
            "Epoch 58/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 138.0199 - root_mean_squared_error: 16.2002 - val_loss: 210.0675 - val_root_mean_squared_error: 16.1535\n",
            "Epoch 59/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 136.7797 - root_mean_squared_error: 16.1364 - val_loss: 205.3883 - val_root_mean_squared_error: 16.0912\n",
            "Epoch 60/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 138.4041 - root_mean_squared_error: 16.0746 - val_loss: 206.7735 - val_root_mean_squared_error: 16.0317\n",
            "Epoch 61/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 138.4193 - root_mean_squared_error: 16.0157 - val_loss: 220.8021 - val_root_mean_squared_error: 15.9729\n",
            "Epoch 62/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 136.9281 - root_mean_squared_error: 15.9574 - val_loss: 215.0735 - val_root_mean_squared_error: 15.9152\n",
            "Epoch 63/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 137.4505 - root_mean_squared_error: 15.9001 - val_loss: 212.0224 - val_root_mean_squared_error: 15.8593\n",
            "Epoch 64/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 135.3514 - root_mean_squared_error: 15.8443 - val_loss: 204.7097 - val_root_mean_squared_error: 15.8047\n",
            "Epoch 65/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 135.1111 - root_mean_squared_error: 15.7899 - val_loss: 216.6149 - val_root_mean_squared_error: 15.7512\n",
            "Epoch 66/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 135.3789 - root_mean_squared_error: 15.7367 - val_loss: 205.6519 - val_root_mean_squared_error: 15.6988\n",
            "Epoch 67/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 131.7534 - root_mean_squared_error: 15.6843 - val_loss: 214.5969 - val_root_mean_squared_error: 15.6477\n",
            "Epoch 68/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 137.7778 - root_mean_squared_error: 15.6344 - val_loss: 216.4417 - val_root_mean_squared_error: 15.5977\n",
            "Epoch 69/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 135.6475 - root_mean_squared_error: 15.5847 - val_loss: 206.8896 - val_root_mean_squared_error: 15.5494\n",
            "Epoch 70/70\n",
            "84/84 [==============================] - 2s 25ms/step - loss: 132.7525 - root_mean_squared_error: 15.5362 - val_loss: 203.4249 - val_root_mean_squared_error: 15.5009\n",
            "13.73476329163818\n",
            "[[110.246414 ]\n",
            " [117.29669  ]\n",
            " [ 52.19132  ]\n",
            " [ 92.00627  ]\n",
            " [104.84265  ]\n",
            " [103.355736 ]\n",
            " [ 97.2959   ]\n",
            " [ 82.189606 ]\n",
            " [106.25549  ]\n",
            " [ 91.27409  ]\n",
            " [ 91.706985 ]\n",
            " [ 92.78199  ]\n",
            " [ 88.59161  ]\n",
            " [107.18717  ]\n",
            " [ 99.00008  ]\n",
            " [ 95.6795   ]\n",
            " [ 48.190723 ]\n",
            " [ 32.379223 ]\n",
            " [ 88.87322  ]\n",
            " [ 19.322172 ]\n",
            " [ 64.974686 ]\n",
            " [114.91342  ]\n",
            " [115.7626   ]\n",
            " [ 19.979595 ]\n",
            " [118.199524 ]\n",
            " [113.36264  ]\n",
            " [ 83.46742  ]\n",
            " [107.00906  ]\n",
            " [107.87457  ]\n",
            " [112.04837  ]\n",
            " [ 10.682636 ]\n",
            " [ 42.612766 ]\n",
            " [115.577545 ]\n",
            " [  3.8442354]\n",
            " [  9.011695 ]\n",
            " [ 26.543781 ]\n",
            " [ 25.20264  ]\n",
            " [ 43.47393  ]\n",
            " [122.37402  ]\n",
            " [ 35.22113  ]\n",
            " [ 25.916748 ]\n",
            " [ 12.498814 ]\n",
            " [ 69.19599  ]\n",
            " [ 93.68224  ]\n",
            " [ 86.04907  ]\n",
            " [ 38.84134  ]\n",
            " [115.11711  ]\n",
            " [ 94.35037  ]\n",
            " [ 18.077684 ]\n",
            " [ 91.63125  ]\n",
            " [ 94.860634 ]\n",
            " [ 28.189384 ]\n",
            " [ 25.30235  ]\n",
            " [117.36218  ]\n",
            " [107.07555  ]\n",
            " [ 17.550615 ]\n",
            " [108.61662  ]\n",
            " [ 42.788006 ]\n",
            " [111.93276  ]\n",
            " [111.19766  ]\n",
            " [ 22.534397 ]\n",
            " [ 40.589252 ]\n",
            " [ 75.81547  ]\n",
            " [ 23.479675 ]\n",
            " [122.340454 ]\n",
            " [ 18.814884 ]\n",
            " [112.46477  ]\n",
            " [  7.918789 ]\n",
            " [106.942444 ]\n",
            " [ 87.639824 ]\n",
            " [101.4563   ]\n",
            " [ 54.471474 ]\n",
            " [102.80734  ]\n",
            " [100.43121  ]\n",
            " [102.34563  ]\n",
            " [  7.7866755]\n",
            " [ 25.89259  ]\n",
            " [122.05652  ]\n",
            " [ 83.612206 ]\n",
            " [100.714516 ]\n",
            " [ 10.354157 ]\n",
            " [  7.514222 ]\n",
            " [124.84776  ]\n",
            " [ 78.288956 ]\n",
            " [129.47803  ]\n",
            " [108.17081  ]\n",
            " [122.358025 ]\n",
            " [119.91439  ]\n",
            " [112.50459  ]\n",
            " [ 23.86248  ]\n",
            " [ 29.42185  ]\n",
            " [ 21.083073 ]\n",
            " [ 48.91007  ]\n",
            " [ 74.9916   ]\n",
            " [ 96.185875 ]\n",
            " [107.771    ]\n",
            " [ 88.50579  ]\n",
            " [ 75.26413  ]\n",
            " [116.37518  ]\n",
            " [ 17.862019 ]]\n",
            "188.64372267733165\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}