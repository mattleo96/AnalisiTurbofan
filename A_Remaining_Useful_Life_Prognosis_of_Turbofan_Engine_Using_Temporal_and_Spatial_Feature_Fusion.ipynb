{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "A Remaining Useful Life Prognosis of Turbofan Engine Using Temporal and Spatial Feature Fusion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYySwFJKj-JW",
        "outputId": "ca2d0a94-6e94-4393-c304-d99e47a231a8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LSTM,Dropout,GRU,MaxPooling1D,Flatten,concatenate\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Concatenate,Bidirectional\n",
        "from keras.layers.convolutional import Conv1D\n",
        "import tensorflow as tf\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed,Activation\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras import Input,Model\n",
        "FD1_train = pd.read_csv(\"train_FD001.txt\",delimiter=\" \",header = None)\n",
        "FD1_test = pd.read_csv(\"test_FD001.txt\",delimiter=\" \",header = None)\n",
        "RUL_file=pd.read_csv(\"RUL_FD001.txt\",header = None)\n",
        "FD1_test=FD1_test.drop([26, 27], axis = 1)\n",
        "columns = {0:'unit_number',1:'time_in_cycles',2:'opSetting1',3:'opSetting2',4:'opSetting3',5:'sensor1',6:'sensor2',\n",
        "           7:'sensor3',8:'sensor4',9:'sensor5',10:'sensor6',11:'sensor7',12:'sensor8',13:'sensor9',14:'sensor10',\n",
        "           15:'sensor11',16:'sensor12',17:'sensor13',18:'sensor14',19:'sensor15',20:'sensor16',\n",
        "           21:'sensor17',22:'sensor18',23:'sensor19',24:'sensor20',25:'sensor21'}\n",
        "FD1_test.columns=columns\n",
        "FD1_test = FD1_test.rename(columns=columns)\n",
        "#FD1_test=FD1_test.drop(columns = ['opSetting1','opSetting2','opSetting3','sensor1','sensor5','sensor6','sensor10','sensor16','sensor18','sensor19','sensor17'], axis =1)\n",
        "\n",
        "FD1_test.drop(FD1_test.loc[FD1_test['unit_number']==1].index, inplace=True)\n",
        "FD1_test.drop(FD1_test.loc[FD1_test['unit_number']==2].index, inplace=True)\n",
        "FD1_test.drop(FD1_test.loc[FD1_test['unit_number']==14].index, inplace=True)\n",
        "FD1_test.drop(FD1_test.loc[FD1_test['unit_number']==22].index, inplace=True)\n",
        "FD1_test.drop(FD1_test.loc[FD1_test['unit_number']==25].index, inplace=True)\n",
        "FD1_test.drop(FD1_test.loc[FD1_test['unit_number']==39].index, inplace=True)\n",
        "FD1_test.drop(FD1_test.loc[FD1_test['unit_number']==85].index, inplace=True)\n",
        "\n",
        "FD1_train=FD1_train.drop([26, 27], axis = 1)\n",
        "columns = {0:'unit_number',1:'time_in_cycles',2:'opSetting1',3:'opSetting2',4:'opSetting3',5:'sensor1',6:'sensor2',\n",
        "           7:'sensor3',8:'sensor4',9:'sensor5',10:'sensor6',11:'sensor7',12:'sensor8',13:'sensor9',14:'sensor10',\n",
        "           15:'sensor11',16:'sensor12',17:'sensor13',18:'sensor14',19:'sensor15',20:'sensor16',\n",
        "           21:'sensor17',22:'sensor18',23:'sensor19',24:'sensor20',25:'sensor21'}\n",
        "FD1_train = FD1_train.rename(columns=columns)\n",
        "#FD1_train=FD1_train.drop(columns = ['opSetting1','opSetting2','opSetting3','sensor1','sensor5','sensor6','sensor10','sensor16','sensor18','sensor19','sensor17'], axis =1)\n",
        "def Calcolo_RUL(df):\n",
        "    df_copy=df.copy()\n",
        "    gruppo=df_copy.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
        "    gruppo.columns = ['unit_number','max_cycles_fu']\n",
        "    df_copy = df_copy.merge(gruppo, on=['unit_number'], how='left')\n",
        "    df['RUL'] = df_copy['max_cycles_fu'] - df_copy['time_in_cycles']\n",
        "    return df\n",
        "Calcolo_RUL(FD1_train)\n",
        "\n",
        "cols_normalize = FD1_train.columns.difference(\n",
        "    ['unit_number', 'time_in_cycles', 'RUL'])  \n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(FD1_train[cols_normalize]),\n",
        "                             columns=cols_normalize,\n",
        "                             index=FD1_train.index)\n",
        "\n",
        "join_df = FD1_train[FD1_train.columns.difference(cols_normalize)].join(norm_train_df)\n",
        "FD1_train = join_df.reindex(columns=FD1_train.columns)\n",
        "\n",
        "cols_normalizetest = FD1_test.columns.difference(\n",
        "    ['unit_number', 'time_in_cycles'])  \n",
        "\n",
        "norm_train_df_test = pd.DataFrame(min_max_scaler.transform(FD1_test[cols_normalizetest]),\n",
        "                             columns=cols_normalizetest,\n",
        "                             index=FD1_test.index)\n",
        "\n",
        "join_df = FD1_test[FD1_test.columns.difference(cols_normalizetest)].join(norm_train_df_test)\n",
        "FD1_test = join_df.reindex(columns=FD1_test.columns)\n",
        "FD1_test=FD1_test.drop(columns = ['time_in_cycles'], axis =1)\n",
        "data_cols= FD1_test.columns\n",
        "\n",
        "def prepare_test_data(df):\n",
        "    data_list = []\n",
        "    for unit_number in df.unit_number.unique():\n",
        "        unit = df[df.unit_number == unit_number]\n",
        "        data_list.append(np.array(unit[data_cols])[-50:, :])\n",
        "    return np.stack(data_list)\n",
        "FD1_test=prepare_test_data(FD1_test)\n",
        "FD1_test=FD1_test[:,:,1:]\n",
        "\n",
        "rul_clip_limit = 130\n",
        "FD1_train=FD1_train.clip(upper=rul_clip_limit)\n",
        "\n",
        "FD1_c=FD1_train.copy()\n",
        "FD1_train = FD1_train.drop(['time_in_cycles','RUL'], axis=1)\n",
        "\n",
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    data_array = id_df[seq_cols].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        yield data_array[start:stop, :]\n",
        "\n",
        "seq_gen = (list(gen_sequence(FD1_train[FD1_train['unit_number']==unit_number],50, FD1_train.columns))\n",
        "           for unit_number in FD1_train['unit_number'].unique())\n",
        "\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "seq_array=seq_array[:,:,1:]\n",
        "seq_array1=seq_array[:7815,:,:]\n",
        "seq_array2=seq_array[7816:,:,:]\n",
        "\n",
        "\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "    data_array = id_df[label].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    return data_array[seq_length:num_elements, :]\n",
        "\n",
        "label_gen = [gen_labels(FD1_c[FD1_c['unit_number']==id], 50, ['RUL'])\n",
        "             for id in FD1_c['unit_number'].unique()]\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "a=Input(shape=(50,24))\n",
        "x1=Conv1D(128,1,padding='same',activation='relu')(a)\n",
        "x1=MaxPooling1D(pool_size=2,padding='same',strides=2)(x1)\n",
        "x1=Conv1D(64,1,padding='same',activation='relu')(x1)\n",
        "x1=MaxPooling1D(pool_size=2,padding='same',strides=2)(x1)\n",
        "x1=Conv1D(32,1,padding='same',activation='relu')(x1)\n",
        "x1=MaxPooling1D(pool_size=2,padding='same',strides=2)(x1)\n",
        "x1=Dropout(0.2)(x1)\n",
        "x1 = Model(inputs=a, outputs=x1)\n",
        "\n",
        "b=Input(shape=(50,24))\n",
        "y1=LSTM(128, return_sequences=True)(b)\n",
        "y1=LSTM(64, return_sequences=True)(y1)\n",
        "y1=LSTM(32, return_sequences=True)(y1)\n",
        "y1 = Model(inputs=b, outputs=y1)\n",
        "\n",
        "combined = concatenate([x1.output, y1.output],axis=1)\n",
        "z=Conv1D(128,1,activation='relu')(combined)\n",
        "z=MaxPooling1D(pool_size=2,padding='same',strides=2)(z)\n",
        "z= Flatten()(z)\n",
        "z = Dense(128,activation=\"relu\")(z)\n",
        "z = Dense(32,activation=\"relu\")(z)\n",
        "z = Dense(1,activation=\"relu\")(z)\n",
        "\n",
        "model = Model(inputs=[y1.input, x1.input], outputs=z)\n",
        "model.compile(loss='mean_squared_error', optimizer='adam',metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "model.fit([seq_array1,seq_array2],label_array,batch_size=90,epochs=60,verbose=1,validation_split=0.05)\n",
        "y_pred=model.predict([FD1_test,FD1_test])\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "#from sklearn.metrics import mean_absolute_percentage_error\n",
        "RUL_file.drop([1,2,14,22,25,39,85], inplace=True)\n",
        "\n",
        "print(sqrt(mean_squared_error(RUL_file, y_pred)))\n",
        "print(y_pred)\n",
        "print((mean_squared_error(RUL_file, y_pred)))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "83/83 [==============================] - 8s 32ms/step - loss: 3403.2204 - root_mean_squared_error: 67.3570 - val_loss: 1760.6653 - val_root_mean_squared_error: 47.9352\n",
            "Epoch 2/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 1626.3560 - root_mean_squared_error: 46.6192 - val_loss: 888.3869 - val_root_mean_squared_error: 43.2481\n",
            "Epoch 3/60\n",
            "83/83 [==============================] - 1s 13ms/step - loss: 824.0585 - root_mean_squared_error: 41.8933 - val_loss: 172.0409 - val_root_mean_squared_error: 38.1640\n",
            "Epoch 4/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 309.4188 - root_mean_squared_error: 36.9502 - val_loss: 209.1196 - val_root_mean_squared_error: 34.0086\n",
            "Epoch 5/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 210.4544 - root_mean_squared_error: 33.1497 - val_loss: 292.1857 - val_root_mean_squared_error: 31.0407\n",
            "Epoch 6/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 166.5980 - root_mean_squared_error: 30.4051 - val_loss: 256.3683 - val_root_mean_squared_error: 28.8166\n",
            "Epoch 7/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 151.4684 - root_mean_squared_error: 28.3268 - val_loss: 305.4931 - val_root_mean_squared_error: 27.1149\n",
            "Epoch 8/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 141.9279 - root_mean_squared_error: 26.7266 - val_loss: 161.0415 - val_root_mean_squared_error: 25.7187\n",
            "Epoch 9/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 143.5522 - root_mean_squared_error: 25.3968 - val_loss: 177.9627 - val_root_mean_squared_error: 24.5608\n",
            "Epoch 10/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 134.6532 - root_mean_squared_error: 24.2908 - val_loss: 172.5589 - val_root_mean_squared_error: 23.5851\n",
            "Epoch 11/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 128.1383 - root_mean_squared_error: 23.3526 - val_loss: 224.9905 - val_root_mean_squared_error: 22.7463\n",
            "Epoch 12/60\n",
            "83/83 [==============================] - 1s 13ms/step - loss: 113.9108 - root_mean_squared_error: 22.5424 - val_loss: 149.1279 - val_root_mean_squared_error: 22.0031\n",
            "Epoch 13/60\n",
            "83/83 [==============================] - 1s 13ms/step - loss: 121.2425 - root_mean_squared_error: 21.8249 - val_loss: 145.3908 - val_root_mean_squared_error: 21.3467\n",
            "Epoch 14/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 105.8733 - root_mean_squared_error: 21.1838 - val_loss: 162.3239 - val_root_mean_squared_error: 20.7576\n",
            "Epoch 15/60\n",
            "83/83 [==============================] - 1s 13ms/step - loss: 112.8812 - root_mean_squared_error: 20.6171 - val_loss: 168.6401 - val_root_mean_squared_error: 20.2352\n",
            "Epoch 16/60\n",
            "83/83 [==============================] - 1s 13ms/step - loss: 114.6411 - root_mean_squared_error: 20.1082 - val_loss: 177.1240 - val_root_mean_squared_error: 19.7758\n",
            "Epoch 17/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 103.5957 - root_mean_squared_error: 19.6599 - val_loss: 178.8695 - val_root_mean_squared_error: 19.3585\n",
            "Epoch 18/60\n",
            "83/83 [==============================] - 1s 13ms/step - loss: 99.5006 - root_mean_squared_error: 19.2521 - val_loss: 143.8314 - val_root_mean_squared_error: 18.9580\n",
            "Epoch 19/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 92.2792 - root_mean_squared_error: 18.8573 - val_loss: 160.9490 - val_root_mean_squared_error: 18.5910\n",
            "Epoch 20/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 100.5635 - root_mean_squared_error: 18.5012 - val_loss: 168.9740 - val_root_mean_squared_error: 18.2673\n",
            "Epoch 21/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 101.7826 - root_mean_squared_error: 18.1872 - val_loss: 144.7905 - val_root_mean_squared_error: 17.9574\n",
            "Epoch 22/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 89.8681 - root_mean_squared_error: 17.8780 - val_loss: 275.1177 - val_root_mean_squared_error: 17.6761\n",
            "Epoch 23/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 88.8247 - root_mean_squared_error: 17.6060 - val_loss: 171.7779 - val_root_mean_squared_error: 17.4065\n",
            "Epoch 24/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 81.2266 - root_mean_squared_error: 17.3363 - val_loss: 169.2787 - val_root_mean_squared_error: 17.1474\n",
            "Epoch 25/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 75.2325 - root_mean_squared_error: 17.0800 - val_loss: 140.2473 - val_root_mean_squared_error: 16.8998\n",
            "Epoch 26/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 77.4577 - root_mean_squared_error: 16.8359 - val_loss: 133.5834 - val_root_mean_squared_error: 16.6623\n",
            "Epoch 27/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 71.6310 - root_mean_squared_error: 16.6014 - val_loss: 170.0013 - val_root_mean_squared_error: 16.4364\n",
            "Epoch 28/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 78.0291 - root_mean_squared_error: 16.3817 - val_loss: 265.3919 - val_root_mean_squared_error: 16.2388\n",
            "Epoch 29/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 75.4794 - root_mean_squared_error: 16.1892 - val_loss: 181.7388 - val_root_mean_squared_error: 16.0425\n",
            "Epoch 30/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 67.5522 - root_mean_squared_error: 15.9918 - val_loss: 239.4731 - val_root_mean_squared_error: 15.8495\n",
            "Epoch 31/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 62.8293 - root_mean_squared_error: 15.8015 - val_loss: 122.0109 - val_root_mean_squared_error: 15.6628\n",
            "Epoch 32/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 59.6781 - root_mean_squared_error: 15.6136 - val_loss: 126.3622 - val_root_mean_squared_error: 15.4790\n",
            "Epoch 33/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 63.3705 - root_mean_squared_error: 15.4331 - val_loss: 170.6704 - val_root_mean_squared_error: 15.3089\n",
            "Epoch 34/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 55.9539 - root_mean_squared_error: 15.2651 - val_loss: 163.5843 - val_root_mean_squared_error: 15.1405\n",
            "Epoch 35/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 54.9313 - root_mean_squared_error: 15.0979 - val_loss: 152.8095 - val_root_mean_squared_error: 14.9790\n",
            "Epoch 36/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 55.4536 - root_mean_squared_error: 14.9383 - val_loss: 114.7173 - val_root_mean_squared_error: 14.8216\n",
            "Epoch 37/60\n",
            "83/83 [==============================] - 1s 13ms/step - loss: 49.3790 - root_mean_squared_error: 14.7808 - val_loss: 158.0878 - val_root_mean_squared_error: 14.6678\n",
            "Epoch 38/60\n",
            "83/83 [==============================] - 1s 13ms/step - loss: 44.9242 - root_mean_squared_error: 14.6289 - val_loss: 140.9874 - val_root_mean_squared_error: 14.5183\n",
            "Epoch 39/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 39.3765 - root_mean_squared_error: 14.4792 - val_loss: 175.1728 - val_root_mean_squared_error: 14.3729\n",
            "Epoch 40/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 40.4992 - root_mean_squared_error: 14.3359 - val_loss: 126.7188 - val_root_mean_squared_error: 14.2324\n",
            "Epoch 41/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 36.3277 - root_mean_squared_error: 14.1953 - val_loss: 163.9948 - val_root_mean_squared_error: 14.0942\n",
            "Epoch 42/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 31.9070 - root_mean_squared_error: 14.0584 - val_loss: 188.2619 - val_root_mean_squared_error: 13.9601\n",
            "Epoch 43/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 33.6381 - root_mean_squared_error: 13.9264 - val_loss: 195.6558 - val_root_mean_squared_error: 13.8329\n",
            "Epoch 44/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 38.3026 - root_mean_squared_error: 13.8017 - val_loss: 131.8716 - val_root_mean_squared_error: 13.7093\n",
            "Epoch 45/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 47.8894 - root_mean_squared_error: 13.6803 - val_loss: 164.4072 - val_root_mean_squared_error: 13.5954\n",
            "Epoch 46/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 26.6560 - root_mean_squared_error: 13.5636 - val_loss: 170.1277 - val_root_mean_squared_error: 13.4734\n",
            "Epoch 47/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 24.7498 - root_mean_squared_error: 13.4419 - val_loss: 153.9006 - val_root_mean_squared_error: 13.3539\n",
            "Epoch 48/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 23.3292 - root_mean_squared_error: 13.3236 - val_loss: 147.1998 - val_root_mean_squared_error: 13.2367\n",
            "Epoch 49/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 20.5539 - root_mean_squared_error: 13.2063 - val_loss: 137.4408 - val_root_mean_squared_error: 13.1229\n",
            "Epoch 50/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 24.5531 - root_mean_squared_error: 13.0943 - val_loss: 113.6035 - val_root_mean_squared_error: 13.0129\n",
            "Epoch 51/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 19.1519 - root_mean_squared_error: 12.9838 - val_loss: 130.3300 - val_root_mean_squared_error: 12.9028\n",
            "Epoch 52/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 21.3214 - root_mean_squared_error: 12.8751 - val_loss: 135.5436 - val_root_mean_squared_error: 12.7981\n",
            "Epoch 53/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 16.6674 - root_mean_squared_error: 12.7705 - val_loss: 119.5939 - val_root_mean_squared_error: 12.6935\n",
            "Epoch 54/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 15.3918 - root_mean_squared_error: 12.6663 - val_loss: 128.6613 - val_root_mean_squared_error: 12.5910\n",
            "Epoch 55/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 15.5786 - root_mean_squared_error: 12.5647 - val_loss: 109.5333 - val_root_mean_squared_error: 12.4919\n",
            "Epoch 56/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 23.8344 - root_mean_squared_error: 12.4677 - val_loss: 135.7173 - val_root_mean_squared_error: 12.3981\n",
            "Epoch 57/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 11.9229 - root_mean_squared_error: 12.3729 - val_loss: 161.8880 - val_root_mean_squared_error: 12.3025\n",
            "Epoch 58/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 14.3067 - root_mean_squared_error: 12.2787 - val_loss: 122.1198 - val_root_mean_squared_error: 12.2106\n",
            "Epoch 59/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 11.9183 - root_mean_squared_error: 12.1862 - val_loss: 140.8665 - val_root_mean_squared_error: 12.1191\n",
            "Epoch 60/60\n",
            "83/83 [==============================] - 1s 14ms/step - loss: 12.1777 - root_mean_squared_error: 12.0960 - val_loss: 139.9961 - val_root_mean_squared_error: 12.0303\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd48b2f8d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "22.98828877315611\n",
            "[[ 51.00096  ]\n",
            " [ 80.46722  ]\n",
            " [ 92.832726 ]\n",
            " [ 92.91474  ]\n",
            " [ 94.81119  ]\n",
            " [ 62.736805 ]\n",
            " [106.451454 ]\n",
            " [ 71.83026  ]\n",
            " [ 83.31699  ]\n",
            " [ 75.74255  ]\n",
            " [ 79.74192  ]\n",
            " [115.84201  ]\n",
            " [ 88.60725  ]\n",
            " [ 50.9038   ]\n",
            " [ 21.815588 ]\n",
            " [ 77.252594 ]\n",
            " [ 14.582715 ]\n",
            " [ 56.133823 ]\n",
            " [119.274284 ]\n",
            " [ 19.766953 ]\n",
            " [ 90.461464 ]\n",
            " [ 83.337204 ]\n",
            " [ 77.31803  ]\n",
            " [ 68.73903  ]\n",
            " [ 66.712326 ]\n",
            " [  5.1259947]\n",
            " [ 44.628105 ]\n",
            " [ 96.3747   ]\n",
            " [  4.1964607]\n",
            " [ 12.7652645]\n",
            " [ 25.66443  ]\n",
            " [ 17.162092 ]\n",
            " [ 45.655933 ]\n",
            " [ 27.949093 ]\n",
            " [ 12.3821745]\n",
            " [  6.78236  ]\n",
            " [ 52.748726 ]\n",
            " [112.77518  ]\n",
            " [ 84.64341  ]\n",
            " [ 40.30439  ]\n",
            " [115.22691  ]\n",
            " [104.27077  ]\n",
            " [ 12.019368 ]\n",
            " [ 71.10267  ]\n",
            " [ 89.93028  ]\n",
            " [ 21.834562 ]\n",
            " [ 27.410105 ]\n",
            " [ 98.47016  ]\n",
            " [118.92674  ]\n",
            " [  9.428238 ]\n",
            " [ 81.083855 ]\n",
            " [ 36.051743 ]\n",
            " [107.96674  ]\n",
            " [ 84.77406  ]\n",
            " [ 25.057493 ]\n",
            " [ 40.16947  ]\n",
            " [ 53.658726 ]\n",
            " [ 24.294664 ]\n",
            " [119.11255  ]\n",
            " [ 14.273672 ]\n",
            " [117.363396 ]\n",
            " [  6.986512 ]\n",
            " [119.38792  ]\n",
            " [ 67.831894 ]\n",
            " [ 91.05785  ]\n",
            " [ 57.40418  ]\n",
            " [ 94.93456  ]\n",
            " [ 84.95181  ]\n",
            " [102.49136  ]\n",
            " [  5.7260666]\n",
            " [ 31.997057 ]\n",
            " [141.12952  ]\n",
            " [ 86.14379  ]\n",
            " [ 68.08429  ]\n",
            " [  7.96502  ]\n",
            " [  9.208729 ]\n",
            " [111.716095 ]\n",
            " [ 60.881626 ]\n",
            " [ 73.97767  ]\n",
            " [116.57779  ]\n",
            " [ 98.21108  ]\n",
            " [119.15866  ]\n",
            " [ 25.016024 ]\n",
            " [ 24.364483 ]\n",
            " [ 19.06644  ]\n",
            " [ 42.753235 ]\n",
            " [ 52.94134  ]\n",
            " [112.41912  ]\n",
            " [ 80.75075  ]\n",
            " [ 83.24434  ]\n",
            " [ 63.77133  ]\n",
            " [118.29111  ]\n",
            " [ 15.557304 ]]\n",
            "528.4614207180153\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}