{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Leveraging the Power of the Combination of CNN and Bi-directional LSTM Networks for Aircraft Engine RUL Estimation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1DxfpUctB0E",
        "outputId": "81c8f0b2-8d52-4c53-9aec-f42525f89397"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LSTM,Dropout,GRU,MaxPooling1D,Flatten,concatenate\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Concatenate,Bidirectional\n",
        "from keras.layers.convolutional import Conv1D\n",
        "import tensorflow as tf\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed,Activation\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras import Input,Model\n",
        "\n",
        "FD1_train = pd.read_csv(\"train_FD001.txt\",delimiter=\" \",header = None)\n",
        "FD1_test = pd.read_csv(\"test_FD001.txt\",delimiter=\" \",header = None)\n",
        "RUL_file=pd.read_csv(\"RUL_FD001.txt\",header = None)\n",
        "\n",
        "FD1_test=FD1_test.drop([26, 27], axis = 1)\n",
        "columns = {0:'unit_number',1:'time_in_cycles',2:'opSetting1',3:'opSetting2',4:'opSetting3',5:'sensor1',6:'sensor2',\n",
        "           7:'sensor3',8:'sensor4',9:'sensor5',10:'sensor6',11:'sensor7',12:'sensor8',13:'sensor9',14:'sensor10',\n",
        "           15:'sensor11',16:'sensor12',17:'sensor13',18:'sensor14',19:'sensor15',20:'sensor16',\n",
        "           21:'sensor17',22:'sensor18',23:'sensor19',24:'sensor20',25:'sensor21'}\n",
        "FD1_test.columns=columns\n",
        "FD1_test = FD1_test.rename(columns=columns)\n",
        "FD1_test=FD1_test.drop(columns = ['opSetting1','opSetting2','opSetting3','sensor1','sensor5','sensor6','sensor10','sensor16','sensor18','sensor19','sensor17'], axis =1)\n",
        "\n",
        "\n",
        "\n",
        "FD1_train=FD1_train.drop([26, 27], axis = 1)\n",
        "columns = {0:'unit_number',1:'time_in_cycles',2:'opSetting1',3:'opSetting2',4:'opSetting3',5:'sensor1',6:'sensor2',\n",
        "           7:'sensor3',8:'sensor4',9:'sensor5',10:'sensor6',11:'sensor7',12:'sensor8',13:'sensor9',14:'sensor10',\n",
        "           15:'sensor11',16:'sensor12',17:'sensor13',18:'sensor14',19:'sensor15',20:'sensor16',\n",
        "           21:'sensor17',22:'sensor18',23:'sensor19',24:'sensor20',25:'sensor21'}\n",
        "FD1_train = FD1_train.rename(columns=columns)\n",
        "FD1_train=FD1_train.drop(columns = ['opSetting1','opSetting2','opSetting3','sensor1','sensor5','sensor6','sensor10','sensor16','sensor18','sensor19','sensor17'], axis =1)\n",
        "\n",
        "# calcolo RUL\n",
        "def Calcolo_RUL(df): \n",
        "    df_copy=df.copy()\n",
        "    gruppo=df_copy.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
        "    gruppo.columns = ['unit_number','max_cycles_fu']\n",
        "    df_copy = df_copy.merge(gruppo, on=['unit_number'], how='left')\n",
        "    df['RUL'] = df_copy['max_cycles_fu'] - df_copy['time_in_cycles']\n",
        "    return df\n",
        "Calcolo_RUL(FD1_train)\n",
        "#normalizzazione train test\n",
        "cols_normalize = FD1_train.columns.difference( #non considero unit_number,time_in_cycles,RUL per normalizzazione\n",
        "    ['unit_number', 'time_in_cycles', 'RUL'])  \n",
        "\n",
        "min_max_scaler = StandardScaler()\n",
        "\n",
        "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(FD1_train[cols_normalize]),\n",
        "                             columns=cols_normalize,\n",
        "                             index=FD1_train.index)\n",
        "\n",
        "join_df = FD1_train[FD1_train.columns.difference(cols_normalize)].join(norm_train_df)\n",
        "FD1_train = join_df.reindex(columns=FD1_train.columns)\n",
        "\n",
        "cols_normalizetest = FD1_test.columns.difference(  #non considero unit_number,time_in_cyclesper normalizzazione\n",
        "    ['unit_number', 'time_in_cycles'])  \n",
        "\n",
        "norm_train_df_test = pd.DataFrame(min_max_scaler.transform(FD1_test[cols_normalizetest]),\n",
        "                             columns=cols_normalizetest,\n",
        "                             index=FD1_test.index)\n",
        "\n",
        "join_df = FD1_test[FD1_test.columns.difference(cols_normalizetest)].join(norm_train_df_test)\n",
        "FD1_test = join_df.reindex(columns=FD1_test.columns)\n",
        "FD1_test=FD1_test.drop(columns = ['time_in_cycles'], axis =1)\n",
        "data_cols= FD1_test.columns\n",
        "##\n",
        "## reshape dati test\n",
        "def prepare_test_data(df):\n",
        "    data_list = []\n",
        "    for unit_number in df.unit_number.unique():\n",
        "        unit = df[df.unit_number == unit_number]\n",
        "        data_list.append(np.array(unit[data_cols])[-31:, :])\n",
        "    return np.stack(data_list)\n",
        "FD1_test=prepare_test_data(FD1_test)\n",
        "FD1_test=FD1_test[:,:,1:]\n",
        "\n",
        "\n",
        "## upper bound per RUL\n",
        "rul_clip_limit = 120\n",
        "FD1_train=FD1_train.clip(upper=rul_clip_limit)\n",
        "\n",
        "FD1_c=FD1_train.copy()\n",
        "FD1_train = FD1_train.drop(['RUL','time_in_cycles'], axis=1)\n",
        "## reshape dati di train\n",
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    data_array = id_df[seq_cols].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        yield data_array[start:stop, :]\n",
        "\n",
        "seq_gen = (list(gen_sequence(FD1_train[FD1_train['unit_number']==unit_number],31, FD1_train.columns))\n",
        "           for unit_number in FD1_train['unit_number'].unique())\n",
        "\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "\n",
        "\n",
        "seq_array=seq_array[:,:,1:] #elimino unit_number dal train\n",
        "print(seq_array.shape) # dimensione dei dati di train\n",
        "\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "    data_array = id_df[label].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    return data_array[seq_length:num_elements, :]\n",
        "\n",
        "label_gen = [gen_labels(FD1_c[FD1_c['unit_number']==id], 31, ['RUL'])\n",
        "             for id in FD1_c['unit_number'].unique()]\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "model= Sequential()\n",
        "model.add(Conv1D(10,1,padding='same',activation='relu'))\n",
        "model.add(Conv1D(10,1,padding='same',activation='relu'))\n",
        "model.add(Conv1D(10,1,padding='same',activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(100, input_shape=(31, 14), return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(100, input_shape=(31, 14), return_sequences=False)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation=\"relu\"))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='RMSprop',metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "model.fit(seq_array,label_array ,batch_size=200,epochs=50,verbose=1,validation_split=0.05)\n",
        "y_pred= model.predict(FD1_test)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "RUL_file=pd.read_csv(\"RUL_FD001.txt\",header = None)\n",
        "print(sqrt(mean_squared_error(RUL_file, y_pred)))\n",
        "print(y_pred)\n",
        "print((mean_squared_error(RUL_file, y_pred)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17531, 31, 13)\n",
            "Epoch 1/50\n",
            "84/84 [==============================] - 11s 37ms/step - loss: 5289.3733 - root_mean_squared_error: 77.6244 - val_loss: 3474.1638 - val_root_mean_squared_error: 66.6055\n",
            "Epoch 2/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 3164.8248 - root_mean_squared_error: 64.7435 - val_loss: 2128.0444 - val_root_mean_squared_error: 60.1150\n",
            "Epoch 3/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 1886.1282 - root_mean_squared_error: 58.4834 - val_loss: 1205.8651 - val_root_mean_squared_error: 54.3609\n",
            "Epoch 4/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 1060.4283 - root_mean_squared_error: 52.9643 - val_loss: 663.5556 - val_root_mean_squared_error: 49.4299\n",
            "Epoch 5/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 585.8757 - root_mean_squared_error: 48.2696 - val_loss: 424.0364 - val_root_mean_squared_error: 45.3258\n",
            "Epoch 6/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 353.5708 - root_mean_squared_error: 44.3855 - val_loss: 302.6209 - val_root_mean_squared_error: 42.0341\n",
            "Epoch 7/50\n",
            "84/84 [==============================] - 1s 17ms/step - loss: 298.8150 - root_mean_squared_error: 41.2945 - val_loss: 494.5755 - val_root_mean_squared_error: 39.4457\n",
            "Epoch 8/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 267.0411 - root_mean_squared_error: 38.8532 - val_loss: 296.7077 - val_root_mean_squared_error: 37.3336\n",
            "Epoch 9/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 238.5954 - root_mean_squared_error: 36.8393 - val_loss: 333.9681 - val_root_mean_squared_error: 35.5726\n",
            "Epoch 10/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 232.6757 - root_mean_squared_error: 35.1589 - val_loss: 501.7564 - val_root_mean_squared_error: 34.0931\n",
            "Epoch 11/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 220.9819 - root_mean_squared_error: 33.7408 - val_loss: 260.5120 - val_root_mean_squared_error: 32.8088\n",
            "Epoch 12/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 205.4960 - root_mean_squared_error: 32.4963 - val_loss: 252.3192 - val_root_mean_squared_error: 31.6832\n",
            "Epoch 13/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 199.6232 - root_mean_squared_error: 31.4074 - val_loss: 441.4270 - val_root_mean_squared_error: 30.6982\n",
            "Epoch 14/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 197.0078 - root_mean_squared_error: 30.4584 - val_loss: 236.7668 - val_root_mean_squared_error: 29.8124\n",
            "Epoch 15/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 193.2289 - root_mean_squared_error: 29.5951 - val_loss: 227.3235 - val_root_mean_squared_error: 29.0208\n",
            "Epoch 16/50\n",
            "84/84 [==============================] - 1s 17ms/step - loss: 180.3875 - root_mean_squared_error: 28.8220 - val_loss: 256.4912 - val_root_mean_squared_error: 28.3022\n",
            "Epoch 17/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 175.3723 - root_mean_squared_error: 28.1220 - val_loss: 279.3194 - val_root_mean_squared_error: 27.6469\n",
            "Epoch 18/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 168.2002 - root_mean_squared_error: 27.4821 - val_loss: 237.6474 - val_root_mean_squared_error: 27.0467\n",
            "Epoch 19/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 165.8432 - root_mean_squared_error: 26.8952 - val_loss: 250.0528 - val_root_mean_squared_error: 26.4934\n",
            "Epoch 20/50\n",
            "84/84 [==============================] - 1s 17ms/step - loss: 165.3477 - root_mean_squared_error: 26.3549 - val_loss: 250.1058 - val_root_mean_squared_error: 25.9850\n",
            "Epoch 21/50\n",
            "84/84 [==============================] - 1s 17ms/step - loss: 156.6834 - root_mean_squared_error: 25.8550 - val_loss: 234.7504 - val_root_mean_squared_error: 25.5150\n",
            "Epoch 22/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 163.1481 - root_mean_squared_error: 25.3962 - val_loss: 260.0395 - val_root_mean_squared_error: 25.0766\n",
            "Epoch 23/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 155.7672 - root_mean_squared_error: 24.9643 - val_loss: 272.7486 - val_root_mean_squared_error: 24.6695\n",
            "Epoch 24/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 154.7295 - root_mean_squared_error: 24.5638 - val_loss: 248.5387 - val_root_mean_squared_error: 24.2863\n",
            "Epoch 25/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 149.6404 - root_mean_squared_error: 24.1870 - val_loss: 267.2818 - val_root_mean_squared_error: 23.9250\n",
            "Epoch 26/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 149.4094 - root_mean_squared_error: 23.8332 - val_loss: 2308.8176 - val_root_mean_squared_error: 23.6487\n",
            "Epoch 27/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 388.4447 - root_mean_squared_error: 23.6277 - val_loss: 281.9451 - val_root_mean_squared_error: 23.4005\n",
            "Epoch 28/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 145.9328 - root_mean_squared_error: 23.3178 - val_loss: 257.6836 - val_root_mean_squared_error: 23.0956\n",
            "Epoch 29/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 150.5363 - root_mean_squared_error: 23.0183 - val_loss: 309.7089 - val_root_mean_squared_error: 22.8119\n",
            "Epoch 30/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 146.4644 - root_mean_squared_error: 22.7394 - val_loss: 280.7210 - val_root_mean_squared_error: 22.5399\n",
            "Epoch 31/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 139.8544 - root_mean_squared_error: 22.4700 - val_loss: 313.2022 - val_root_mean_squared_error: 22.2810\n",
            "Epoch 32/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 143.5646 - root_mean_squared_error: 22.2142 - val_loss: 324.3107 - val_root_mean_squared_error: 22.0353\n",
            "Epoch 33/50\n",
            "84/84 [==============================] - 1s 17ms/step - loss: 137.8335 - root_mean_squared_error: 21.9715 - val_loss: 288.1229 - val_root_mean_squared_error: 21.7986\n",
            "Epoch 34/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 138.1002 - root_mean_squared_error: 21.7380 - val_loss: 325.7968 - val_root_mean_squared_error: 21.5726\n",
            "Epoch 35/50\n",
            "84/84 [==============================] - 1s 17ms/step - loss: 134.6262 - root_mean_squared_error: 21.5159 - val_loss: 377.7339 - val_root_mean_squared_error: 21.3605\n",
            "Epoch 36/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 126.6107 - root_mean_squared_error: 21.3040 - val_loss: 218.6012 - val_root_mean_squared_error: 21.1503\n",
            "Epoch 37/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 124.7990 - root_mean_squared_error: 21.0949 - val_loss: 293.3647 - val_root_mean_squared_error: 20.9476\n",
            "Epoch 38/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 124.7941 - root_mean_squared_error: 20.8960 - val_loss: 242.0832 - val_root_mean_squared_error: 20.7552\n",
            "Epoch 39/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 120.5557 - root_mean_squared_error: 20.7038 - val_loss: 259.6671 - val_root_mean_squared_error: 20.5695\n",
            "Epoch 40/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 127.6631 - root_mean_squared_error: 20.5219 - val_loss: 259.0960 - val_root_mean_squared_error: 20.3903\n",
            "Epoch 41/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 121.1524 - root_mean_squared_error: 20.3436 - val_loss: 257.8495 - val_root_mean_squared_error: 20.2174\n",
            "Epoch 42/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 122.0284 - root_mean_squared_error: 20.1729 - val_loss: 336.4903 - val_root_mean_squared_error: 20.0527\n",
            "Epoch 43/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 119.9753 - root_mean_squared_error: 20.0106 - val_loss: 297.3122 - val_root_mean_squared_error: 19.8972\n",
            "Epoch 44/50\n",
            "84/84 [==============================] - 1s 17ms/step - loss: 116.0167 - root_mean_squared_error: 19.8544 - val_loss: 271.4237 - val_root_mean_squared_error: 19.7391\n",
            "Epoch 45/50\n",
            "84/84 [==============================] - 1s 17ms/step - loss: 115.5400 - root_mean_squared_error: 19.6988 - val_loss: 284.3159 - val_root_mean_squared_error: 19.5876\n",
            "Epoch 46/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 114.7670 - root_mean_squared_error: 19.5491 - val_loss: 337.1351 - val_root_mean_squared_error: 19.4425\n",
            "Epoch 47/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 112.8473 - root_mean_squared_error: 19.4052 - val_loss: 264.1413 - val_root_mean_squared_error: 19.3004\n",
            "Epoch 48/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 113.3420 - root_mean_squared_error: 19.2634 - val_loss: 367.2118 - val_root_mean_squared_error: 19.1636\n",
            "Epoch 49/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 115.3984 - root_mean_squared_error: 19.1296 - val_loss: 260.1523 - val_root_mean_squared_error: 19.0310\n",
            "Epoch 50/50\n",
            "84/84 [==============================] - 1s 16ms/step - loss: 104.7798 - root_mean_squared_error: 18.9959 - val_loss: 308.8340 - val_root_mean_squared_error: 18.8997\n",
            "15.626734560768353\n",
            "[[116.32724 ]\n",
            " [117.03761 ]\n",
            " [ 73.90961 ]\n",
            " [ 80.50695 ]\n",
            " [102.931946]\n",
            " [107.10441 ]\n",
            " [112.923935]\n",
            " [ 85.8865  ]\n",
            " [114.10867 ]\n",
            " [ 85.75792 ]\n",
            " [103.02603 ]\n",
            " [110.27682 ]\n",
            " [ 88.29985 ]\n",
            " [ 99.98445 ]\n",
            " [116.419815]\n",
            " [117.16433 ]\n",
            " [ 53.27858 ]\n",
            " [ 29.192074]\n",
            " [113.85976 ]\n",
            " [ 25.606392]\n",
            " [ 67.20804 ]\n",
            " [118.085396]\n",
            " [117.147644]\n",
            " [ 29.198387]\n",
            " [117.3115  ]\n",
            " [117.209145]\n",
            " [ 78.24219 ]\n",
            " [113.84877 ]\n",
            " [110.44659 ]\n",
            " [111.91174 ]\n",
            " [ 20.80608 ]\n",
            " [ 58.019066]\n",
            " [117.718285]\n",
            " [ 11.046606]\n",
            " [ 31.444523]\n",
            " [ 40.89545 ]\n",
            " [ 27.45853 ]\n",
            " [ 68.62166 ]\n",
            " [116.633575]\n",
            " [ 52.851048]\n",
            " [ 28.088486]\n",
            " [ 17.529072]\n",
            " [ 59.803604]\n",
            " [118.02983 ]\n",
            " [ 98.57895 ]\n",
            " [ 45.72267 ]\n",
            " [104.56961 ]\n",
            " [ 81.68782 ]\n",
            " [ 32.03518 ]\n",
            " [112.913414]\n",
            " [118.055664]\n",
            " [ 38.486065]\n",
            " [ 35.72807 ]\n",
            " [115.986534]\n",
            " [118.11136 ]\n",
            " [ 34.57705 ]\n",
            " [113.10962 ]\n",
            " [ 64.21946 ]\n",
            " [105.718124]\n",
            " [115.25905 ]\n",
            " [ 20.57505 ]\n",
            " [ 52.138805]\n",
            " [ 90.42878 ]\n",
            " [ 30.197098]\n",
            " [118.14183 ]\n",
            " [ 31.562777]\n",
            " [118.01258 ]\n",
            " [ 15.317508]\n",
            " [118.31621 ]\n",
            " [104.523346]\n",
            " [116.42309 ]\n",
            " [ 80.19612 ]\n",
            " [117.53176 ]\n",
            " [112.96487 ]\n",
            " [117.44575 ]\n",
            " [ 16.001633]\n",
            " [ 43.062656]\n",
            " [119.71249 ]\n",
            " [ 68.0961  ]\n",
            " [ 86.68726 ]\n",
            " [ 25.470808]\n",
            " [ 15.904265]\n",
            " [117.97145 ]\n",
            " [ 84.05026 ]\n",
            " [114.42824 ]\n",
            " [107.17649 ]\n",
            " [111.9206  ]\n",
            " [112.766975]\n",
            " [110.981865]\n",
            " [ 38.12216 ]\n",
            " [ 42.07604 ]\n",
            " [ 41.510098]\n",
            " [ 54.281475]\n",
            " [ 81.81577 ]\n",
            " [116.16068 ]\n",
            " [115.47853 ]\n",
            " [ 88.46948 ]\n",
            " [ 57.138428]\n",
            " [115.725586]\n",
            " [ 27.732372]]\n",
            "244.19483303271213\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}