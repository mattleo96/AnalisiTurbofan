{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Remaining Useful Life Prediction of Turbofan Engine Using Hybrid Model Based on Autoencoder and Bidirectional Long Short-Term Memory[BLSTM].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCVbN13fGnJc",
        "outputId": "4c1e126f-b274-450a-975d-8e91b114c8b1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LSTM,Dropout,GRU,MaxPooling1D,Flatten,concatenate\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Concatenate,Bidirectional\n",
        "from keras.layers.convolutional import Conv1D\n",
        "import tensorflow as tf\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed,Activation\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras import Input,Model\n",
        "\n",
        "FD1_train = pd.read_csv(\"train_FD001.txt\",delimiter=\" \",header = None)\n",
        "FD1_test = pd.read_csv(\"test_FD001.txt\",delimiter=\" \",header = None)\n",
        "RUL_file=pd.read_csv(\"RUL_FD001.txt\",header = None)\n",
        "\n",
        "FD1_test=FD1_test.drop([26, 27], axis = 1)\n",
        "columns = {0:'unit_number',1:'time_in_cycles',2:'opSetting1',3:'opSetting2',4:'opSetting3',5:'sensor1',6:'sensor2',\n",
        "           7:'sensor3',8:'sensor4',9:'sensor5',10:'sensor6',11:'sensor7',12:'sensor8',13:'sensor9',14:'sensor10',\n",
        "           15:'sensor11',16:'sensor12',17:'sensor13',18:'sensor14',19:'sensor15',20:'sensor16',\n",
        "           21:'sensor17',22:'sensor18',23:'sensor19',24:'sensor20',25:'sensor21'}\n",
        "FD1_test.columns=columns\n",
        "FD1_test = FD1_test.rename(columns=columns)\n",
        "FD1_test=FD1_test.drop(columns = ['opSetting1','opSetting2','opSetting3','sensor1','sensor5','sensor6','sensor10','sensor16','sensor18','sensor19','sensor17'], axis =1)\n",
        "\n",
        "\n",
        "\n",
        "FD1_train=FD1_train.drop([26, 27], axis = 1)\n",
        "columns = {0:'unit_number',1:'time_in_cycles',2:'opSetting1',3:'opSetting2',4:'opSetting3',5:'sensor1',6:'sensor2',\n",
        "           7:'sensor3',8:'sensor4',9:'sensor5',10:'sensor6',11:'sensor7',12:'sensor8',13:'sensor9',14:'sensor10',\n",
        "           15:'sensor11',16:'sensor12',17:'sensor13',18:'sensor14',19:'sensor15',20:'sensor16',\n",
        "           21:'sensor17',22:'sensor18',23:'sensor19',24:'sensor20',25:'sensor21'}\n",
        "FD1_train = FD1_train.rename(columns=columns)\n",
        "FD1_train=FD1_train.drop(columns = ['opSetting1','opSetting2','opSetting3','sensor1','sensor5','sensor6','sensor10','sensor16','sensor18','sensor19','sensor17'], axis =1)\n",
        "\n",
        "# calcolo RUL\n",
        "def Calcolo_RUL(df): \n",
        "    df_copy=df.copy()\n",
        "    gruppo=df_copy.groupby('unit_number')['time_in_cycles'].max().reset_index()\n",
        "    gruppo.columns = ['unit_number','max_cycles_fu']\n",
        "    df_copy = df_copy.merge(gruppo, on=['unit_number'], how='left')\n",
        "    df['RUL'] = df_copy['max_cycles_fu'] - df_copy['time_in_cycles']\n",
        "    return df\n",
        "Calcolo_RUL(FD1_train)\n",
        "#normalizzazione train test\n",
        "cols_normalize = FD1_train.columns.difference( #non considero unit_number,time_in_cycles,RUL per normalizzazione\n",
        "    ['unit_number', 'time_in_cycles', 'RUL'])  \n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(FD1_train[cols_normalize]),\n",
        "                             columns=cols_normalize,\n",
        "                             index=FD1_train.index)\n",
        "\n",
        "join_df = FD1_train[FD1_train.columns.difference(cols_normalize)].join(norm_train_df)\n",
        "FD1_train = join_df.reindex(columns=FD1_train.columns)\n",
        "\n",
        "cols_normalizetest = FD1_test.columns.difference(  #non considero unit_number,time_in_cyclesper normalizzazione\n",
        "    ['unit_number', 'time_in_cycles'])  \n",
        "\n",
        "norm_train_df_test = pd.DataFrame(min_max_scaler.transform(FD1_test[cols_normalizetest]),\n",
        "                             columns=cols_normalizetest,\n",
        "                             index=FD1_test.index)\n",
        "\n",
        "join_df = FD1_test[FD1_test.columns.difference(cols_normalizetest)].join(norm_train_df_test)\n",
        "FD1_test = join_df.reindex(columns=FD1_test.columns)\n",
        "FD1_test=FD1_test.drop(columns = ['time_in_cycles'], axis =1)\n",
        "data_cols= FD1_test.columns\n",
        "##\n",
        "## reshape dati test\n",
        "def prepare_test_data(df):\n",
        "    data_list = []\n",
        "    for unit_number in df.unit_number.unique():\n",
        "        unit = df[df.unit_number == unit_number]\n",
        "        data_list.append(np.array(unit[data_cols])[-31:, :])\n",
        "    return np.stack(data_list)\n",
        "FD1_test=prepare_test_data(FD1_test)\n",
        "FD1_test=FD1_test[:,:,1:]\n",
        "\n",
        "\n",
        "## upper bound per RUL\n",
        "rul_clip_limit = 120\n",
        "FD1_train=FD1_train.clip(upper=rul_clip_limit)\n",
        "\n",
        "FD1_c=FD1_train.copy()\n",
        "FD1_train = FD1_train.drop(['RUL','time_in_cycles'], axis=1)\n",
        "## reshape dati di train\n",
        "def gen_sequence(id_df, seq_length, seq_cols):\n",
        "    data_array = id_df[seq_cols].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
        "        yield data_array[start:stop, :]\n",
        "\n",
        "seq_gen = (list(gen_sequence(FD1_train[FD1_train['unit_number']==unit_number],31, FD1_train.columns))\n",
        "           for unit_number in FD1_train['unit_number'].unique())\n",
        "\n",
        "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
        "\n",
        "\n",
        "seq_array=seq_array[:,:,1:] #elimino unit_number dal train\n",
        "print(seq_array.shape) # dimensione dei dati di train\n",
        "\n",
        "def gen_labels(id_df, seq_length, label):\n",
        "    data_array = id_df[label].values\n",
        "    num_elements = data_array.shape[0]\n",
        "    return data_array[seq_length:num_elements, :]\n",
        "\n",
        "label_gen = [gen_labels(FD1_c[FD1_c['unit_number']==id], 31, ['RUL'])\n",
        "             for id in FD1_c['unit_number'].unique()]\n",
        "label_array = np.concatenate(label_gen).astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model= Sequential()\n",
        "model.add(Bidirectional(LSTM(100,input_shape=(31,14),activation='tanh',return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Bidirectional(LSTM(50,input_shape=(31,14),activation='tanh',return_sequences=False)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(30))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='RMSprop',metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "model.fit(seq_array,label_array ,batch_size=128,epochs=50,verbose=1,validation_split=0.05)\n",
        "y_pred= model.predict(FD1_test)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "RUL_file=pd.read_csv(\"RUL_FD001.txt\",header = None)\n",
        "print(sqrt(mean_squared_error(RUL_file, y_pred)))\n",
        "print(y_pred)\n",
        "print((mean_squared_error(RUL_file, y_pred)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17531, 31, 13)\n",
            "Epoch 1/50\n",
            "131/131 [==============================] - 11s 24ms/step - loss: 3231.1457 - root_mean_squared_error: 65.6809 - val_loss: 657.3588 - val_root_mean_squared_error: 43.4896\n",
            "Epoch 2/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 543.1850 - root_mean_squared_error: 40.3418 - val_loss: 387.8692 - val_root_mean_squared_error: 34.3951\n",
            "Epoch 3/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 437.2193 - root_mean_squared_error: 33.1483 - val_loss: 418.1264 - val_root_mean_squared_error: 30.4172\n",
            "Epoch 4/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 363.2671 - root_mean_squared_error: 29.6843 - val_loss: 416.7973 - val_root_mean_squared_error: 27.9258\n",
            "Epoch 5/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 314.4686 - root_mean_squared_error: 27.4259 - val_loss: 313.6676 - val_root_mean_squared_error: 26.1293\n",
            "Epoch 6/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 270.6236 - root_mean_squared_error: 25.7410 - val_loss: 239.7309 - val_root_mean_squared_error: 24.7420\n",
            "Epoch 7/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 244.4161 - root_mean_squared_error: 24.4302 - val_loss: 213.6683 - val_root_mean_squared_error: 23.6394\n",
            "Epoch 8/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 233.9381 - root_mean_squared_error: 23.3891 - val_loss: 206.3106 - val_root_mean_squared_error: 22.7397\n",
            "Epoch 9/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 214.9380 - root_mean_squared_error: 22.5273 - val_loss: 298.8495 - val_root_mean_squared_error: 21.9963\n",
            "Epoch 10/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 213.6941 - root_mean_squared_error: 21.8217 - val_loss: 274.4077 - val_root_mean_squared_error: 21.3718\n",
            "Epoch 11/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 214.7044 - root_mean_squared_error: 21.2251 - val_loss: 271.9569 - val_root_mean_squared_error: 20.8504\n",
            "Epoch 12/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 202.8999 - root_mean_squared_error: 20.7225 - val_loss: 254.0831 - val_root_mean_squared_error: 20.3819\n",
            "Epoch 13/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 206.7745 - root_mean_squared_error: 20.2736 - val_loss: 325.7579 - val_root_mean_squared_error: 19.9836\n",
            "Epoch 14/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 206.1773 - root_mean_squared_error: 19.8909 - val_loss: 172.4321 - val_root_mean_squared_error: 19.6245\n",
            "Epoch 15/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 191.3788 - root_mean_squared_error: 19.5325 - val_loss: 230.8014 - val_root_mean_squared_error: 19.2936\n",
            "Epoch 16/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 189.8930 - root_mean_squared_error: 19.2140 - val_loss: 216.7400 - val_root_mean_squared_error: 18.9936\n",
            "Epoch 17/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 192.7197 - root_mean_squared_error: 18.9226 - val_loss: 260.1106 - val_root_mean_squared_error: 18.7315\n",
            "Epoch 18/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 186.4424 - root_mean_squared_error: 18.6637 - val_loss: 160.9052 - val_root_mean_squared_error: 18.4814\n",
            "Epoch 19/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 184.1962 - root_mean_squared_error: 18.4181 - val_loss: 231.2951 - val_root_mean_squared_error: 18.2562\n",
            "Epoch 20/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 180.6037 - root_mean_squared_error: 18.2001 - val_loss: 168.8696 - val_root_mean_squared_error: 18.0427\n",
            "Epoch 21/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 184.4264 - root_mean_squared_error: 17.9911 - val_loss: 331.3087 - val_root_mean_squared_error: 17.8479\n",
            "Epoch 22/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 178.7891 - root_mean_squared_error: 17.8042 - val_loss: 210.4340 - val_root_mean_squared_error: 17.6716\n",
            "Epoch 23/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 173.1421 - root_mean_squared_error: 17.6249 - val_loss: 200.7107 - val_root_mean_squared_error: 17.5011\n",
            "Epoch 24/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 175.9979 - root_mean_squared_error: 17.4579 - val_loss: 233.7127 - val_root_mean_squared_error: 17.3426\n",
            "Epoch 25/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 166.0744 - root_mean_squared_error: 17.3016 - val_loss: 261.3545 - val_root_mean_squared_error: 17.1955\n",
            "Epoch 26/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 169.9862 - root_mean_squared_error: 17.1578 - val_loss: 202.9725 - val_root_mean_squared_error: 17.0585\n",
            "Epoch 27/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 166.2334 - root_mean_squared_error: 17.0216 - val_loss: 219.4657 - val_root_mean_squared_error: 16.9272\n",
            "Epoch 28/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 170.4952 - root_mean_squared_error: 16.8951 - val_loss: 184.1176 - val_root_mean_squared_error: 16.8057\n",
            "Epoch 29/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 169.3099 - root_mean_squared_error: 16.7743 - val_loss: 274.8900 - val_root_mean_squared_error: 16.6904\n",
            "Epoch 30/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 165.7640 - root_mean_squared_error: 16.6604 - val_loss: 207.9164 - val_root_mean_squared_error: 16.5791\n",
            "Epoch 31/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 166.8820 - root_mean_squared_error: 16.5519 - val_loss: 239.5391 - val_root_mean_squared_error: 16.4748\n",
            "Epoch 32/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 166.7257 - root_mean_squared_error: 16.4497 - val_loss: 186.0396 - val_root_mean_squared_error: 16.3739\n",
            "Epoch 33/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 162.6384 - root_mean_squared_error: 16.3473 - val_loss: 169.3333 - val_root_mean_squared_error: 16.2755\n",
            "Epoch 34/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 160.7433 - root_mean_squared_error: 16.2498 - val_loss: 539.5474 - val_root_mean_squared_error: 16.1938\n",
            "Epoch 35/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 167.2807 - root_mean_squared_error: 16.1745 - val_loss: 227.9534 - val_root_mean_squared_error: 16.1102\n",
            "Epoch 36/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 159.9254 - root_mean_squared_error: 16.0883 - val_loss: 176.1141 - val_root_mean_squared_error: 16.0227\n",
            "Epoch 37/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 154.7620 - root_mean_squared_error: 15.9998 - val_loss: 242.2377 - val_root_mean_squared_error: 15.9391\n",
            "Epoch 38/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 153.7738 - root_mean_squared_error: 15.9183 - val_loss: 169.8801 - val_root_mean_squared_error: 15.8581\n",
            "Epoch 39/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 154.2657 - root_mean_squared_error: 15.8373 - val_loss: 255.4562 - val_root_mean_squared_error: 15.7816\n",
            "Epoch 40/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 152.1043 - root_mean_squared_error: 15.7616 - val_loss: 202.0846 - val_root_mean_squared_error: 15.7026\n",
            "Epoch 41/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 151.4713 - root_mean_squared_error: 15.6832 - val_loss: 192.1968 - val_root_mean_squared_error: 15.6276\n",
            "Epoch 42/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 142.8699 - root_mean_squared_error: 15.6075 - val_loss: 142.1058 - val_root_mean_squared_error: 15.5521\n",
            "Epoch 43/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 144.2056 - root_mean_squared_error: 15.5328 - val_loss: 198.7554 - val_root_mean_squared_error: 15.4810\n",
            "Epoch 44/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 147.9624 - root_mean_squared_error: 15.4637 - val_loss: 215.7539 - val_root_mean_squared_error: 15.4139\n",
            "Epoch 45/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 143.8967 - root_mean_squared_error: 15.3967 - val_loss: 237.4010 - val_root_mean_squared_error: 15.3478\n",
            "Epoch 46/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 141.1394 - root_mean_squared_error: 15.3301 - val_loss: 475.1902 - val_root_mean_squared_error: 15.2874\n",
            "Epoch 47/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 141.2755 - root_mean_squared_error: 15.2736 - val_loss: 176.1680 - val_root_mean_squared_error: 15.2262\n",
            "Epoch 48/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 139.6430 - root_mean_squared_error: 15.2092 - val_loss: 185.6354 - val_root_mean_squared_error: 15.1625\n",
            "Epoch 49/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 135.7066 - root_mean_squared_error: 15.1458 - val_loss: 214.4706 - val_root_mean_squared_error: 15.1002\n",
            "Epoch 50/50\n",
            "131/131 [==============================] - 2s 12ms/step - loss: 132.4300 - root_mean_squared_error: 15.0846 - val_loss: 249.5395 - val_root_mean_squared_error: 15.0401\n",
            "14.685725819007171\n",
            "[[121.72343  ]\n",
            " [120.55429  ]\n",
            " [ 50.703426 ]\n",
            " [105.24113  ]\n",
            " [114.49771  ]\n",
            " [103.94453  ]\n",
            " [118.62196  ]\n",
            " [101.4629   ]\n",
            " [119.335915 ]\n",
            " [ 87.984276 ]\n",
            " [ 89.27691  ]\n",
            " [114.66142  ]\n",
            " [ 89.95862  ]\n",
            " [110.7797   ]\n",
            " [121.15999  ]\n",
            " [117.31918  ]\n",
            " [ 53.10365  ]\n",
            " [ 21.288727 ]\n",
            " [114.7501   ]\n",
            " [ 12.16294  ]\n",
            " [ 66.886665 ]\n",
            " [120.00995  ]\n",
            " [123.08495  ]\n",
            " [ 20.72999  ]\n",
            " [121.78656  ]\n",
            " [120.528786 ]\n",
            " [ 80.743515 ]\n",
            " [118.499146 ]\n",
            " [105.25757  ]\n",
            " [113.189575 ]\n",
            " [  7.0423994]\n",
            " [ 51.072433 ]\n",
            " [120.84247  ]\n",
            " [  4.908326 ]\n",
            " [ 13.577029 ]\n",
            " [ 19.5488   ]\n",
            " [ 22.013105 ]\n",
            " [ 52.83534  ]\n",
            " [122.90895  ]\n",
            " [ 30.635862 ]\n",
            " [ 16.539392 ]\n",
            " [  9.076813 ]\n",
            " [ 61.87326  ]\n",
            " [106.91723  ]\n",
            " [ 94.153275 ]\n",
            " [ 44.74219  ]\n",
            " [113.61944  ]\n",
            " [101.17932  ]\n",
            " [ 13.113506 ]\n",
            " [118.417656 ]\n",
            " [112.95436  ]\n",
            " [ 31.359179 ]\n",
            " [ 28.204334 ]\n",
            " [122.00961  ]\n",
            " [122.09322  ]\n",
            " [ 16.10871  ]\n",
            " [115.48548  ]\n",
            " [ 39.59846  ]\n",
            " [119.326324 ]\n",
            " [117.528564 ]\n",
            " [ 16.723846 ]\n",
            " [ 45.638294 ]\n",
            " [ 78.3121   ]\n",
            " [ 21.605598 ]\n",
            " [123.27164  ]\n",
            " [ 17.549776 ]\n",
            " [122.22393  ]\n",
            " [  5.365152 ]\n",
            " [115.093124 ]\n",
            " [ 98.68086  ]\n",
            " [119.40331  ]\n",
            " [ 77.17189  ]\n",
            " [120.3201   ]\n",
            " [115.19231  ]\n",
            " [116.59447  ]\n",
            " [  6.340276 ]\n",
            " [ 28.370358 ]\n",
            " [124.54538  ]\n",
            " [ 66.25587  ]\n",
            " [109.986664 ]\n",
            " [  6.844688 ]\n",
            " [  9.120675 ]\n",
            " [123.95264  ]\n",
            " [ 70.88142  ]\n",
            " [123.84492  ]\n",
            " [110.55606  ]\n",
            " [119.75083  ]\n",
            " [120.28699  ]\n",
            " [120.189835 ]\n",
            " [ 23.496553 ]\n",
            " [ 23.11312  ]\n",
            " [ 19.23665  ]\n",
            " [ 42.253193 ]\n",
            " [ 68.04406  ]\n",
            " [116.17242  ]\n",
            " [118.287575 ]\n",
            " [102.88675  ]\n",
            " [ 73.942444 ]\n",
            " [121.15566  ]\n",
            " [ 19.795582 ]]\n",
            "215.67054283105387\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}